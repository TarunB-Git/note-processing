{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc78acd7-4ab7-4251-b766-5be7e23d7eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook root: /home/tar_guest/BTH/note-processing\n",
      "Python version: 3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]\n",
      "\n",
      "Paths summary (change variables at top of cell if needed):\n",
      " DATA_DIR: True /home/tar_guest/BTH/note-processing/data\n",
      " RAW_DIR: True /home/tar_guest/BTH/note-processing/data/raw\n",
      " PROCESSED_DIR: True /home/tar_guest/BTH/note-processing/data/processed\n",
      " MODELS_DIR: True /home/tar_guest/BTH/note-processing/models\n",
      "\n",
      " TASKS file: /home/tar_guest/BTH/note-processing/data/processed/mslatte_tasks.txt -> EXISTS, size=161048 bytes\n",
      "  HEAD:\n",
      "    rearrange closet\n",
      "    meeting tasks\n",
      "    taste of home\n",
      "    bring book in\n",
      "    sociology paper\n",
      " QUESTIONS file: /home/tar_guest/BTH/note-processing/data/processed/msmarcosmall.txt -> EXISTS, size=29477367 bytes\n",
      "  HEAD:\n",
      "    $1000000 in 1994 monry\n",
      "    $10,000 at 5% interest term deposit how much interest\n",
      "    $128 usd to au\n",
      "    $18,000 monthly in rent how much is building worth\n",
      "    $195 australian dollars in pounds\n",
      " SYNTH DEADLINES file: /home/tar_guest/BTH/note-processing/data/processed/synth_deadlines_rich.csv -> EXISTS, size=589386 bytes\n",
      "  HEAD:\n",
      "    sentence,label,label_source\n",
      "    \"Summary memo — until May 8, 2026 at noon.\",deadline,synthetic\n",
      "    code fix - due january 25.,deadline,synthetic\n",
      "    Complete the minutes required by Friday at 2pm.,deadline,synthetic\n",
      "    Please post the slides in Saturday.,deadline,synthetic\n",
      "\n",
      "Library versions:\n",
      " scikit-learn: 1.4.2\n",
      " joblib: 1.4.2\n",
      " pandas: 2.2.2\n",
      " numpy: 1.26.4\n",
      "\n",
      "System memory: total=15 GB, available=12 GB\n",
      "\n",
      "Wrote sentinel: /home/tar_guest/BTH/note-processing/data/processed/notebook_step0_ok.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn, joblib, plotting\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# silence warnings for notebook readability \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = Path.cwd()                     # notebook root\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "MODELS_DIR = ROOT / \"models\"\n",
    "\n",
    "TASKS_PATH = PROCESSED_DIR / \"mslatte_tasks.txt\"          # one sentence per line\n",
    "QUESTIONS_PATH = PROCESSED_DIR / \"msmarcosmall.txt\"       # one sentence per line (large)\n",
    "DEADLINES_SYNTH_PATH = PROCESSED_DIR / \"synth_deadlines_rich.csv\"  # generated synth CSV \n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def quick_info(p: Path, show_head=False, head_lines=5):\n",
    "    if not p.exists():\n",
    "        return f\"{str(p)} -> MISSING\"\n",
    "    try:\n",
    "        sz = p.stat().st_size\n",
    "    except Exception:\n",
    "        sz = None\n",
    "    info = f\"{str(p)} -> EXISTS, size={sz} bytes\"\n",
    "    if show_head and p.is_file():\n",
    "        try:\n",
    "            with p.open('r', encoding='utf8', errors='ignore') as f:\n",
    "                head = [next(f).rstrip() for _ in range(head_lines)]\n",
    "            info += \"\\n  HEAD:\\n    \" + \"\\n    \".join(head)\n",
    "        except StopIteration:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            info += f\"\\n  HEAD ERROR: {e}\"\n",
    "    return info\n",
    "\n",
    "# Print environment summary\n",
    "print(\"Notebook root:\", ROOT)\n",
    "print(\"Python version:\", sys.version.splitlines()[0])\n",
    "print(\"\\nPaths summary (change variables at top of cell if needed):\")\n",
    "print(\" DATA_DIR:\", DATA_DIR.exists(), DATA_DIR)\n",
    "print(\" RAW_DIR:\", RAW_DIR.exists(), RAW_DIR)\n",
    "print(\" PROCESSED_DIR:\", PROCESSED_DIR.exists(), PROCESSED_DIR)\n",
    "print(\" MODELS_DIR:\", MODELS_DIR.exists(), MODELS_DIR)\n",
    "print()\n",
    "print(\" TASKS file:\", quick_info(TASKS_PATH, show_head=True))\n",
    "print(\" QUESTIONS file:\", quick_info(QUESTIONS_PATH, show_head=True))\n",
    "print(\" SYNTH DEADLINES file:\", quick_info(DEADLINES_SYNTH_PATH, show_head=True))\n",
    "\n",
    "# Quick version checks \n",
    "print(\"\\nLibrary versions:\")\n",
    "import sklearn, joblib, pandas, numpy\n",
    "print(\" scikit-learn:\", sklearn.__version__)\n",
    "print(\" joblib:\", joblib.__version__)\n",
    "print(\" pandas:\", pandas.__version__)\n",
    "print(\" numpy:\", numpy.__version__)\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    mem = psutil.virtual_memory()\n",
    "    print(f\"\\nSystem memory: total={mem.total//(1024**3)} GB, available={mem.available//(1024**3)} GB\")\n",
    "except Exception:\n",
    "    print(\"\\npsutil not installed — skipped memory check (optional).\")\n",
    "\n",
    "# If everything imported & paths OK, create a small sentinel file in processed to mark progress.\n",
    "sentinel = PROCESSED_DIR / \"notebook_step0_ok.txt\"\n",
    "sentinel.write_text(f\"Step0 ok at {datetime.now().isoformat()}\\n\", encoding='utf8')\n",
    "print(\"\\nWrote sentinel:\", sentinel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d8cd17-d42a-4b1a-af4e-8a3805d4ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded counts (raw):\n",
      " tasks: 9997\n",
      " questions: 808731\n",
      " deadlines: 9449\n",
      "\n",
      "After per-source normalization & dedupe:\n",
      " tasks: 9997 -> 9997\n",
      " questions: 808731 -> 806586\n",
      " deadlines: 9449 -> 9446\n",
      "\n",
      "=== TASKS (n=9997) ===\n",
      " signoff fraction: 0.00020006001800540162\n",
      " sample normalized -> original (first 6 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>has_signoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rearrange closet</td>\n",
       "      <td>rearrange closet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meeting tasks</td>\n",
       "      <td>meeting tasks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taste of home</td>\n",
       "      <td>taste of home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bring book in</td>\n",
       "      <td>bring book in</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sociology paper</td>\n",
       "      <td>sociology paper</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paper hold</td>\n",
       "      <td>paper hold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence     sentence_orig  has_signoff\n",
       "0  rearrange closet  rearrange closet            0\n",
       "1     meeting tasks     meeting tasks            0\n",
       "2     taste of home     taste of home            0\n",
       "3     bring book in     bring book in            0\n",
       "4   sociology paper   sociology paper            0\n",
       "5        paper hold        paper hold            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUESTIONS (n=806586) ===\n",
      " signoff fraction: 0.0001351374806902178\n",
      " sample normalized -> original (first 6 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>has_signoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000 in 1994 monry</td>\n",
       "      <td>$1000000 in 1994 monry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10,000 at 5% interest term deposit how much in...</td>\n",
       "      <td>$10,000 at 5% interest term deposit how much i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128 usd to au</td>\n",
       "      <td>$128 usd to au</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18,000 monthly in rent how much is building worth</td>\n",
       "      <td>$18,000 monthly in rent how much is building w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195 australian dollars in pounds</td>\n",
       "      <td>$195 australian dollars in pounds</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25 passage on a riverboat in the gold rush to ...</td>\n",
       "      <td>$25 passage on a riverboat in the gold rush to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0                              1000000 in 1994 monry   \n",
       "1  10,000 at 5% interest term deposit how much in...   \n",
       "2                                      128 usd to au   \n",
       "3  18,000 monthly in rent how much is building worth   \n",
       "4                   195 australian dollars in pounds   \n",
       "5  25 passage on a riverboat in the gold rush to ...   \n",
       "\n",
       "                                       sentence_orig  has_signoff  \n",
       "0                             $1000000 in 1994 monry            0  \n",
       "1  $10,000 at 5% interest term deposit how much i...            0  \n",
       "2                                     $128 usd to au            0  \n",
       "3  $18,000 monthly in rent how much is building w...            0  \n",
       "4                  $195 australian dollars in pounds            0  \n",
       "5  $25 passage on a riverboat in the gold rush to...            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEADLINES (n=9446) ===\n",
      " signoff fraction: 0.04583950878678806\n",
      " sample normalized -> original (first 6 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>has_signoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summary memo — until may 8, 2026 at noon</td>\n",
       "      <td>Summary memo — until May 8, 2026 at noon.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>code fix - due january 25</td>\n",
       "      <td>code fix - due january 25.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complete the minutes required by friday at 2pm</td>\n",
       "      <td>Complete the minutes required by Friday at 2pm.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>please post the slides in saturday</td>\n",
       "      <td>Please post the slides in Saturday.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finish the budget deadline for january 26, 202...</td>\n",
       "      <td>Finish the budget deadline for January 26, 202...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>minutes no later than march 17</td>\n",
       "      <td>Minutes no later than March 17.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0           summary memo — until may 8, 2026 at noon   \n",
       "1                          code fix - due january 25   \n",
       "2     complete the minutes required by friday at 2pm   \n",
       "3                 please post the slides in saturday   \n",
       "4  finish the budget deadline for january 26, 202...   \n",
       "5                     minutes no later than march 17   \n",
       "\n",
       "                                       sentence_orig  has_signoff  \n",
       "0          Summary memo — until May 8, 2026 at noon.            0  \n",
       "1                         code fix - due january 25.            0  \n",
       "2    Complete the minutes required by Friday at 2pm.            0  \n",
       "3                Please post the slides in Saturday.            0  \n",
       "4  Finish the budget deadline for January 26, 202...            0  \n",
       "5                    Minutes no later than March 17.            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote processed CSVs to data/processed/: tasks_processed.csv, questions_processed.csv, deadlines_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Load sources, normalize, detect signoffs, and dedupe per-source\n",
    "import re, unicodedata\n",
    "from pathlib import Path\n",
    "\n",
    "# Signoff detection patterns (conservative, common endings).\n",
    "SIGNOFF_PATTERNS = [\n",
    "    r'^\\-+\\s*[A-Za-z]{2,30}\\s*$',   # \"- Name\" single token after dash\n",
    "    r'\\b(thanks|thank you|regards|best|cheers)\\b[.,!]?$',  # end-of-line common words\n",
    "]\n",
    "SIGNOFF_RE = re.compile(r'(' + r'|'.join(SIGNOFF_PATTERNS) + r')', flags=re.I)\n",
    "\n",
    "# Normalization regexes\n",
    "_WS_RE = re.compile(r'\\s+')\n",
    "_TRIM_PUNCT_RE = re.compile(r'^[\\W_]+|[\\W_]+$')   # trim leading/trailing non-word characters\n",
    "\n",
    "def normalize_text_for_model(s: str, strip_signoff: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Produce a normalized string used for dedupe and TF-IDF training.\n",
    "      - We keep sentence_orig unchanged for auditing; sentence_norm is used for dedupe & TF-IDF.\n",
    "    \"\"\"\n",
    "    if s is None:\n",
    "        s = \"\"\n",
    "    s = str(s)\n",
    "    # collapse newlines and whitespace\n",
    "    s = s.replace('\\r',' ').replace('\\n',' ')\n",
    "    s = _WS_RE.sub(' ', s).strip()\n",
    "    # optionally strip signoff-like trailing fragments to avoid punctuation noise\n",
    "    if strip_signoff:\n",
    "        s = re.sub(r'(' + r'|'.join(SIGNOFF_PATTERNS) + r')\\s*$', '', s, flags=re.I).strip()\n",
    "    # unicode normalize and trim leading/trailing punctuation\n",
    "    s = unicodedata.normalize('NFKC', s)\n",
    "    s = _TRIM_PUNCT_RE.sub('', s).strip()\n",
    "    s = _WS_RE.sub(' ', s)\n",
    "    return s.lower()\n",
    "\n",
    "def detect_has_signoff(s: str) -> bool:\n",
    "    \"\"\"Return True if a probable signoff is present at the end of the original line.\"\"\"\n",
    "    if s is None:\n",
    "        return False\n",
    "    s = str(s).replace('\\r',' ').replace('\\n',' ').strip()\n",
    "    # check for signoff regex at end\n",
    "    return bool(re.search(r'(' + r'|'.join(SIGNOFF_PATTERNS) + r')\\s*$', s, flags=re.I))\n",
    "\n",
    "def load_plain_text_lines(path: Path):\n",
    "    with path.open('r', encoding='utf8', errors='ignore') as f:\n",
    "        return [line.rstrip('\\n') for line in f if line.strip()]\n",
    "\n",
    "def load_csv_first_col(path: Path):\n",
    "    # read csv and return first non-empty column as list of strings\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "    # prefer a column named 'sentence' if present\n",
    "    candidates = ['sentence','text','content','note','body']\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return df[c].astype(str).tolist()\n",
    "    # otherwise return everything flattened (first column)\n",
    "    return df.iloc[:,0].astype(str).tolist()\n",
    "\n",
    "def load_source(path: Path):\n",
    "    if not path.exists():\n",
    "        print(f\"WARNING: {path} not found. Returning empty list.\")\n",
    "        return []\n",
    "    if path.suffix.lower() in ('.csv', '.tsv'):\n",
    "        return load_csv_first_col(path)\n",
    "    else:\n",
    "        return load_plain_text_lines(path)\n",
    "\n",
    "tasks_raw = load_source(Path(TASKS_PATH))\n",
    "questions_raw = load_source(Path(QUESTIONS_PATH))\n",
    "deadlines_raw = load_source(Path(DEADLINES_SYNTH_PATH))\n",
    "\n",
    "print(\"Loaded counts (raw):\")\n",
    "print(\" tasks:\", len(tasks_raw))\n",
    "print(\" questions:\", len(questions_raw))\n",
    "print(\" deadlines:\", len(deadlines_raw))\n",
    "print()\n",
    "\n",
    "import pandas as pd\n",
    "def build_df_from_list(lines, label, label_source):\n",
    "    df = pd.DataFrame({'sentence_orig': [str(s) for s in lines]})\n",
    "    # normalized for modeling (strip signoffs)\n",
    "    df['sentence'] = df['sentence_orig'].apply(lambda s: normalize_text_for_model(s, strip_signoff=True))\n",
    "    df['label'] = label\n",
    "    df['label_source'] = label_source\n",
    "    # signoff flag kept separately\n",
    "    df['has_signoff'] = df['sentence_orig'].apply(detect_has_signoff).astype(int)\n",
    "    return df\n",
    "\n",
    "df_tasks = build_df_from_list(tasks_raw, 'task', 'mslatte')\n",
    "df_questions = build_df_from_list(questions_raw, 'question', 'msmarco')\n",
    "df_deadlines = build_df_from_list(deadlines_raw, 'deadline', 'synthetic')\n",
    "\n",
    "def dedupe_per_source(df):\n",
    "    before = len(df)\n",
    "    df2 = df.drop_duplicates(subset=['sentence'], keep='first').reset_index(drop=True)\n",
    "    after = len(df2)\n",
    "    return df2, before, after\n",
    "\n",
    "df_tasks_dedup, t_before, t_after = dedupe_per_source(df_tasks)\n",
    "df_questions_dedup, q_before, q_after = dedupe_per_source(df_questions)\n",
    "df_deadlines_dedup, d_before, d_after = dedupe_per_source(df_deadlines)\n",
    "\n",
    "print(\"After per-source normalization & dedupe:\")\n",
    "print(f\" tasks: {t_before} -> {t_after}\")\n",
    "print(f\" questions: {q_before} -> {q_after}\")\n",
    "print(f\" deadlines: {d_before} -> {d_after}\")\n",
    "print()\n",
    "\n",
    "def diagnostics(df, name, n_samples=6):\n",
    "    print(f\"=== {name} (n={len(df)}) ===\")\n",
    "    print(\" signoff fraction:\", df['has_signoff'].mean())\n",
    "    print(\" sample normalized -> original (first\", n_samples, \"rows):\")\n",
    "    display(df[['sentence','sentence_orig','has_signoff']].head(n_samples))\n",
    "    print()\n",
    "\n",
    "diagnostics(df_tasks_dedup, \"TASKS\")\n",
    "diagnostics(df_questions_dedup, \"QUESTIONS\")\n",
    "diagnostics(df_deadlines_dedup, \"DEADLINES\")\n",
    "\n",
    "processed_dir = Path(\"data/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "df_tasks_dedup.to_csv(processed_dir / \"tasks_processed.csv\", index=False, encoding='utf8')\n",
    "df_questions_dedup.to_csv(processed_dir / \"questions_processed.csv\", index=False, encoding='utf8')\n",
    "df_deadlines_dedup.to_csv(processed_dir / \"deadlines_processed.csv\", index=False, encoding='utf8')\n",
    "print(\"Wrote processed CSVs to data/processed/: tasks_processed.csv, questions_processed.csv, deadlines_processed.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c82bd3-72eb-43c8-8206-d0eff8a64dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processed sources:\n",
      " tasks: 9997 questions: 806586 deadlines: 9446\n",
      "Combined unique sentences: 826026\n",
      "Label distribution after combine: {'question': 806584, 'task': 9996, 'deadline': 9446}\n",
      "Char length mean: 35.16824409885403 median: 33.0\n",
      "\n",
      "Top tokens per label (quick check):\n",
      "\n",
      "Label: task\n",
      "sentence\n",
      "call     748\n",
      "email    436\n",
      "to       426\n",
      "for      395\n",
      "up       320\n",
      "pay      275\n",
      "get      269\n",
      "buy      236\n",
      "clean    202\n",
      "check    194\n",
      "book     190\n",
      "order    171\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label: deadline\n",
      "sentence\n",
      "the         4547\n",
      "due         3264\n",
      "by          2909\n",
      "in          2633\n",
      "at          1924\n",
      "deadline    1230\n",
      "-           1174\n",
      "2026        1133\n",
      "notes        949\n",
      "to           931\n",
      "please       850\n",
      "on           814\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label: question\n",
      "sentence\n",
      "what    291943\n",
      "is      261924\n",
      "the     176461\n",
      "how     144792\n",
      "of      131191\n",
      "a       130984\n",
      "in      117049\n",
      "to      116411\n",
      "does     73389\n",
      "for      69914\n",
      "do       46949\n",
      "are      43131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Random samples per label (inspect these):\n",
      "\n",
      "--- SAMPLE for label task (n=10) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_source</th>\n",
       "      <th>has_signoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>excercise shorts</td>\n",
       "      <td>excercise shorts</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4336</th>\n",
       "      <td>resend invite</td>\n",
       "      <td>resend invite</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>upstairs bathroom fan</td>\n",
       "      <td>upstairs bathroom fan</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>fix timeline</td>\n",
       "      <td>fix timeline</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>shoulder massage</td>\n",
       "      <td>shoulder massage</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>go to all classes</td>\n",
       "      <td>go to all classes</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>spanish hmwk</td>\n",
       "      <td>spanish hmwk</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>email about thesis</td>\n",
       "      <td>email about thesis</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5967</th>\n",
       "      <td>email about project</td>\n",
       "      <td>email about project</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>pay phones</td>\n",
       "      <td>pay phones</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sentence_orig               sentence label_source  has_signoff\n",
       "1078       excercise shorts       excercise shorts      mslatte            0\n",
       "4336          resend invite          resend invite      mslatte            0\n",
       "8966  upstairs bathroom fan  upstairs bathroom fan      mslatte            0\n",
       "5456           fix timeline           fix timeline      mslatte            0\n",
       "2407       shoulder massage       shoulder massage      mslatte            0\n",
       "8995      go to all classes      go to all classes      mslatte            0\n",
       "576            spanish hmwk           spanish hmwk      mslatte            0\n",
       "7441     email about thesis     email about thesis      mslatte            0\n",
       "5967    email about project    email about project      mslatte            0\n",
       "439              pay phones             pay phones      mslatte            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE for label deadline (n=10) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_source</th>\n",
       "      <th>has_signoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14043</th>\n",
       "      <td>Ensure the slides is due November 8, 2026 at 8pm.</td>\n",
       "      <td>ensure the slides is due november 8, 2026 at 8pm</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13551</th>\n",
       "      <td>Hand in the evaluation required by March 7, 2026.</td>\n",
       "      <td>hand in the evaluation required by march 7, 2026</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10757</th>\n",
       "      <td>* Finish the assignment until next Thursday</td>\n",
       "      <td>finish the assignment until next thursday</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11466</th>\n",
       "      <td>• Return the project plan before this Sunday</td>\n",
       "      <td>return the project plan before this sunday</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11042</th>\n",
       "      <td>finish summary memo by this Friday</td>\n",
       "      <td>finish summary memo by this friday</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14292</th>\n",
       "      <td>implement release notes by April 23.</td>\n",
       "      <td>implement release notes by april 23</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18892</th>\n",
       "      <td>Make sure the presentation is before noon.</td>\n",
       "      <td>make sure the presentation is before noon</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13834</th>\n",
       "      <td>Please make sure to email the form deadline in...</td>\n",
       "      <td>please make sure to email the form deadline in...</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19347</th>\n",
       "      <td>expected by: summary memo in 180 days.</td>\n",
       "      <td>expected by: summary memo in 180 days</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16522</th>\n",
       "      <td>Ensure the application is due by Wednesday at ...</td>\n",
       "      <td>ensure the application is due by wednesday at 5pm</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence_orig  \\\n",
       "14043  Ensure the slides is due November 8, 2026 at 8pm.   \n",
       "13551  Hand in the evaluation required by March 7, 2026.   \n",
       "10757        * Finish the assignment until next Thursday   \n",
       "11466       • Return the project plan before this Sunday   \n",
       "11042                 finish summary memo by this Friday   \n",
       "14292               implement release notes by April 23.   \n",
       "18892         Make sure the presentation is before noon.   \n",
       "13834  Please make sure to email the form deadline in...   \n",
       "19347             expected by: summary memo in 180 days.   \n",
       "16522  Ensure the application is due by Wednesday at ...   \n",
       "\n",
       "                                                sentence label_source  \\\n",
       "14043   ensure the slides is due november 8, 2026 at 8pm    synthetic   \n",
       "13551   hand in the evaluation required by march 7, 2026    synthetic   \n",
       "10757          finish the assignment until next thursday    synthetic   \n",
       "11466         return the project plan before this sunday    synthetic   \n",
       "11042                 finish summary memo by this friday    synthetic   \n",
       "14292                implement release notes by april 23    synthetic   \n",
       "18892          make sure the presentation is before noon    synthetic   \n",
       "13834  please make sure to email the form deadline in...    synthetic   \n",
       "19347              expected by: summary memo in 180 days    synthetic   \n",
       "16522  ensure the application is due by wednesday at 5pm    synthetic   \n",
       "\n",
       "       has_signoff  \n",
       "14043            0  \n",
       "13551            0  \n",
       "10757            0  \n",
       "11466            0  \n",
       "11042            0  \n",
       "14292            0  \n",
       "18892            0  \n",
       "13834            0  \n",
       "19347            0  \n",
       "16522            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE for label question (n=10) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label_source</th>\n",
       "      <th>has_signoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168424</th>\n",
       "      <td>hourly rate for pct in usa</td>\n",
       "      <td>hourly rate for pct in usa</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248557</th>\n",
       "      <td>how much does it cost to drive from ct to cali...</td>\n",
       "      <td>how much does it cost to drive from ct to cali...</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249398</th>\n",
       "      <td>how much does it cost to play paintball</td>\n",
       "      <td>how much does it cost to play paintball</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418322</th>\n",
       "      <td>urban definition slang for kutties</td>\n",
       "      <td>urban definition slang for kutties</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212867</th>\n",
       "      <td>how long is the gop going to take to stop trump</td>\n",
       "      <td>how long is the gop going to take to stop trump</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591950</th>\n",
       "      <td>what is medical credentialing definition</td>\n",
       "      <td>what is medical credentialing definition</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66429</th>\n",
       "      <td>can gums heal</td>\n",
       "      <td>can gums heal</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373824</th>\n",
       "      <td>Plasmodium, the parasitic organism that causes...</td>\n",
       "      <td>plasmodium, the parasitic organism that causes...</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300082</th>\n",
       "      <td>how to spell veterinary</td>\n",
       "      <td>how to spell veterinary</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132007</th>\n",
       "      <td>does conduct heat</td>\n",
       "      <td>does conduct heat</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence_orig  \\\n",
       "168424                         hourly rate for pct in usa   \n",
       "248557  how much does it cost to drive from ct to cali...   \n",
       "249398            how much does it cost to play paintball   \n",
       "418322                 urban definition slang for kutties   \n",
       "212867    how long is the gop going to take to stop trump   \n",
       "591950           what is medical credentialing definition   \n",
       "66429                                       can gums heal   \n",
       "373824  Plasmodium, the parasitic organism that causes...   \n",
       "300082                            how to spell veterinary   \n",
       "132007                                  does conduct heat   \n",
       "\n",
       "                                                 sentence label_source  \\\n",
       "168424                         hourly rate for pct in usa      msmarco   \n",
       "248557  how much does it cost to drive from ct to cali...      msmarco   \n",
       "249398            how much does it cost to play paintball      msmarco   \n",
       "418322                 urban definition slang for kutties      msmarco   \n",
       "212867    how long is the gop going to take to stop trump      msmarco   \n",
       "591950           what is medical credentialing definition      msmarco   \n",
       "66429                                       can gums heal      msmarco   \n",
       "373824  plasmodium, the parasitic organism that causes...      msmarco   \n",
       "300082                            how to spell veterinary      msmarco   \n",
       "132007                                  does conduct heat      msmarco   \n",
       "\n",
       "        has_signoff  \n",
       "168424            0  \n",
       "248557            0  \n",
       "249398            0  \n",
       "418322            0  \n",
       "212867            0  \n",
       "591950            0  \n",
       "66429             0  \n",
       "373824            0  \n",
       "300082            0  \n",
       "132007            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote combined CSV: data/processed/combined_dataset.csv\n",
      "Wrote manifest JSON: data/processed/combined_manifest.json\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Merge & balance dataset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "OUT_COMBINED = PROCESSED_DIR / \"combined_dataset.csv\"\n",
    "OUT_MANIFEST = PROCESSED_DIR / \"combined_manifest.json\"\n",
    "\n",
    "# Preference order: if the same normalized sentence appears in multiple sources,\n",
    "# the earlier source in this list is kept.\n",
    "PREFERENCE_ORDER = ['task','deadline','question']\n",
    "\n",
    "# minimal cleaning parameters\n",
    "MIN_SENTENCE_CHARS = 3  \n",
    "MIN_TOKEN_COUNT = 1       # drop empty token sentences\n",
    "\n",
    "def load_processed(path: Path):\n",
    "    if not path.exists():\n",
    "        print(f\"WARNING: {path} not found. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame(columns=['sentence','sentence_orig','label','label_source','has_signoff'])\n",
    "    df = pd.read_csv(path, dtype=str, keep_default_na=False)\n",
    "    # ensure expected columns\n",
    "    expected = ['sentence','sentence_orig','label','label_source','has_signoff']\n",
    "    for c in expected:\n",
    "        if c not in df.columns:\n",
    "            # try to salvage: if sentence_orig missing but sentence exists, copy\n",
    "            if c == 'sentence_orig' and 'sentence' in df.columns:\n",
    "                df['sentence_orig'] = df['sentence']\n",
    "            elif c == 'has_signoff':\n",
    "                df['has_signoff'] = 0\n",
    "            elif c == 'label':\n",
    "                # if label not present, infer by filename\n",
    "                inferred_label = 'unknown'\n",
    "                if 'task' in path.name:\n",
    "                    inferred_label = 'task'\n",
    "                elif 'question' in path.name:\n",
    "                    inferred_label = 'question'\n",
    "                elif 'dead' in path.name:\n",
    "                    inferred_label = 'deadline'\n",
    "                df['label'] = inferred_label\n",
    "            elif c == 'label_source':\n",
    "                df['label_source'] = path.name\n",
    "            else:\n",
    "                df[c] = ''\n",
    "    # ensure types\n",
    "    df['has_signoff'] = df['has_signoff'].fillna('0').astype(int)\n",
    "    return df[ ['sentence','sentence_orig','label','label_source','has_signoff'] ]\n",
    "\n",
    "df_tasks = load_processed(PROCESSED_DIR / \"tasks_processed.csv\")\n",
    "df_questions = load_processed(PROCESSED_DIR / \"questions_processed.csv\")\n",
    "df_deadlines = load_processed(PROCESSED_DIR / \"deadlines_processed.csv\")\n",
    "\n",
    "print(\"Loaded processed sources:\")\n",
    "print(\" tasks:\", len(df_tasks), \"questions:\", len(df_questions), \"deadlines:\", len(df_deadlines))\n",
    "\n",
    "_ws_re = re.compile(r'\\s+')\n",
    "_trim_punct = re.compile(r'^[\\W_]+|[\\W_]+$')\n",
    "def sanitize_norm(s):\n",
    "    if pd.isna(s):\n",
    "        return ''\n",
    "    s = str(s)\n",
    "    s = s.replace('\\r',' ').replace('\\n',' ')\n",
    "    s = _ws_re.sub(' ', s).strip()\n",
    "    s = _trim_punct.sub('', s)\n",
    "    return s.lower()\n",
    "\n",
    "for df in (df_tasks, df_questions, df_deadlines):\n",
    "    df['sentence'] = df['sentence'].astype(str).apply(sanitize_norm)\n",
    "    # drop blank sentences\n",
    "    df.dropna(subset=['sentence'], inplace=True)\n",
    "    df = df[df['sentence'].str.strip().astype(bool)]\n",
    "\n",
    "# Combine with preference: iterate preference order and add unique normalized sentences\n",
    "combined_map = {}   # sentence_norm -> dict(row)\n",
    "sources_in_order = []\n",
    "for label, df in [('task', df_tasks), ('deadline', df_deadlines), ('question', df_questions)]:\n",
    "    sources_in_order.append((label, df))\n",
    "\n",
    "for label, df in sources_in_order:\n",
    "    # iterate rows and add if not present yet\n",
    "    for idx, row in df.iterrows():\n",
    "        s = row['sentence']\n",
    "        if not s or len(s) < MIN_SENTENCE_CHARS:\n",
    "            continue\n",
    "        if s in combined_map:\n",
    "            # already present from a preferred source; skip\n",
    "            continue\n",
    "        # keep provenance and original sentence\n",
    "        combined_map[s] = {\n",
    "            'sentence': s,\n",
    "            'sentence_orig': row.get('sentence_orig', s),\n",
    "            'label': row.get('label', label),\n",
    "            'label_source': row.get('label_source', f\"{label}_source\"),\n",
    "            'has_signoff': int(row.get('has_signoff', 0)),\n",
    "            'provenance': row.get('label_source', f\"{label}_source\")\n",
    "        }\n",
    "\n",
    "# Build final DataFrame\n",
    "combined_df = pd.DataFrame(list(combined_map.values()))\n",
    "print(\"Combined unique sentences:\", len(combined_df))\n",
    "\n",
    "combined_df['token_count'] = combined_df['sentence'].apply(lambda s: len(s.split()))\n",
    "combined_df = combined_df[combined_df['token_count'] >= MIN_TOKEN_COUNT].reset_index(drop=True)\n",
    "\n",
    "# Diagnostics: class counts and basic stats\n",
    "label_counts = combined_df['label'].value_counts().to_dict()\n",
    "print(\"Label distribution after combine:\", label_counts)\n",
    "\n",
    "# Basic length stats\n",
    "combined_df['char_len'] = combined_df['sentence'].str.len()\n",
    "combined_df['word_count'] = combined_df['sentence'].str.split().str.len()\n",
    "print(\"Char length mean:\", combined_df['char_len'].mean(), \"median:\", combined_df['char_len'].median())\n",
    "\n",
    "# Top n-grams per label quick diagnostic (uses simple frequency on tokens; not TF-IDF)\n",
    "def top_ngrams_for_label(df, label, n=12, topk=12):\n",
    "    sub = df[df['label']==label]\n",
    "    tokens = sub['sentence'].str.split().explode()\n",
    "    return tokens.value_counts().head(topk)\n",
    "\n",
    "print(\"\\nTop tokens per label (quick check):\")\n",
    "for lbl in combined_df['label'].unique():\n",
    "    print(\"\\nLabel:\", lbl)\n",
    "    print(top_ngrams_for_label(combined_df, lbl, topk=12).head(12))\n",
    "\n",
    "# Print random samples per class for manual inspection\n",
    "print(\"\\nRandom samples per label (inspect these):\")\n",
    "for lbl in combined_df['label'].unique():\n",
    "    print(f\"\\n--- SAMPLE for label {lbl} (n=10) ---\")\n",
    "    display(combined_df[combined_df['label']==lbl].sample(min(10, len(combined_df[combined_df['label']==lbl])), random_state=42)[['sentence_orig','sentence','label_source','has_signoff']])\n",
    "\n",
    "# Save combined CSV and small manifest\n",
    "combined_df.to_csv(OUT_COMBINED, index=False, encoding='utf8')\n",
    "manifest = {\n",
    "    'created': datetime.now().isoformat(),\n",
    "    'combined_rows': len(combined_df),\n",
    "    'label_counts': combined_df['label'].value_counts().to_dict(),\n",
    "    'preference_order': PREFERENCE_ORDER,\n",
    "    'sources': {\n",
    "        'tasks_processed': len(df_tasks),\n",
    "        'deadlines_processed': len(df_deadlines),\n",
    "        'questions_processed': len(df_questions)\n",
    "    }\n",
    "}\n",
    "with OUT_MANIFEST.open('w', encoding='utf8') as fh:\n",
    "    json.dump(manifest, fh, indent=2)\n",
    "\n",
    "print(\"\\nWrote combined CSV:\", OUT_COMBINED)\n",
    "print(\"Wrote manifest JSON:\", OUT_MANIFEST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca6f434-fe12-4172-97f2-81c0b6a15391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 826026\n",
      "Fitting word TF-IDF (1-3 grams) max_features=100000...\n",
      " X_word shape: (826026, 100000)\n",
      "Fitting char TF-IDF (char_wb 3-5 grams) max_features=30000...\n",
      " X_char shape: (826026, 30000)\n",
      " X_cue shape: (826026, 21)\n",
      "Extracting engineered features...\n",
      "Final combined X_all shape: (826026, 130036)\n",
      "Saved adjusted vectorizers & metadata. X_all ready for training.\n"
     ]
    }
   ],
   "source": [
    "# STEP 3 rework too many features crashed the maxhine\n",
    "import re, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import joblib\n",
    "\n",
    "COMBINED_PATH = Path(\"data/processed/combined_dataset.csv\")\n",
    "MODELS_DIR = Path(\"models\"); MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "assert COMBINED_PATH.exists(), f\"{COMBINED_PATH} missing\"\n",
    "\n",
    "df = pd.read_csv(COMBINED_PATH, dtype=str, keep_default_na=False)\n",
    "sentences = df['sentence'].astype(str).tolist()\n",
    "labels = df['label'].astype(str).tolist()\n",
    "n = len(sentences)\n",
    "print(\"Rows:\", n)\n",
    "\n",
    "WORD_NGRAM_RANGE = (1,3)\n",
    "WORD_MAX_FEATURES = 100000   # reduced to be runnable\n",
    "CHAR_NGRAM_RANGE = (3,5)\n",
    "CHAR_MAX_FEATURES = 30000    # reduced\n",
    "USE_CHAR = True              # set False to drop char features if memory still tight\n",
    "TF_MIN_DF = 3\n",
    "TF_MAX_DF = 0.995\n",
    "CUE_VOCAB = [\n",
    "    \"deadline\",\"due\",\"no later than\",\"due by\",\"deadline for\",\"by\",\"before\",\"until\",\"on or before\",\n",
    "    \"eod\",\"cob\",\"asap\",\"tomorrow\",\"today\",\"next\",\"in\",\"at\",\"before noon\",\"due on\",\"expected by\",\"no later\"\n",
    "]\n",
    "\n",
    "# Word TF-IDF\n",
    "print(\"Fitting word TF-IDF (1-3 grams) max_features=%d...\" % WORD_MAX_FEATURES)\n",
    "tfidf_word = TfidfVectorizer(ngram_range=WORD_NGRAM_RANGE,\n",
    "                             max_features=WORD_MAX_FEATURES,\n",
    "                             min_df=TF_MIN_DF, max_df=TF_MAX_DF,\n",
    "                             strip_accents='unicode', lowercase=True)\n",
    "X_word = tfidf_word.fit_transform(sentences).astype(np.float32)\n",
    "print(\" X_word shape:\", X_word.shape)\n",
    "\n",
    "# Char TF-IDF\n",
    "if USE_CHAR:\n",
    "    print(\"Fitting char TF-IDF (char_wb 3-5 grams) max_features=%d...\" % CHAR_MAX_FEATURES)\n",
    "    tfidf_char = TfidfVectorizer(analyzer='char_wb', ngram_range=CHAR_NGRAM_RANGE,\n",
    "                                 max_features=CHAR_MAX_FEATURES, min_df=TF_MIN_DF)\n",
    "    X_char = tfidf_char.fit_transform(sentences).astype(np.float32)\n",
    "    print(\" X_char shape:\", X_char.shape)\n",
    "else:\n",
    "    X_char = None\n",
    "\n",
    "# cue presence binary\n",
    "cue_vec = CountVectorizer(vocabulary=CUE_VOCAB, binary=True, lowercase=True)\n",
    "X_cue = cue_vec.fit_transform(sentences).astype(np.float32)\n",
    "print(\" X_cue shape:\", X_cue.shape)\n",
    "\n",
    "# engineered features (concise but informative)\n",
    "NUM_RE = re.compile(r'\\d+')\n",
    "WEEKDAY_RE = re.compile(r'\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b', re.I)\n",
    "MONTH_RE = re.compile(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b', re.I)\n",
    "TIME_RE = re.compile(r'\\b(?:\\d{1,2}(:\\d{2})?\\s*(am|pm)|am|pm|noon|midnight|eod|cob)\\b', re.I)\n",
    "RELATIVE_RE = re.compile(r'\\b(tomorrow|today|next|in\\s+\\d+\\s+(?:day|days|week|weeks|month|months|hour|hours|minute|minutes))\\b', re.I)\n",
    "QUESTION_RE = re.compile(r'\\?|\\b(who|what|when|where|why|how|which)\\b', re.I)\n",
    "IMPERATIVE_RE = re.compile(r'^(submit|finish|complete|turn|send|email|deliver|make|do|create|update|fix|upload|prepare|post|hand in|return)\\b', re.I)\n",
    "DURATION_RE = re.compile(r'\\b(hour|hours|minute|minutes|day|days|week|weeks|month|months|year|years)\\b', re.I)\n",
    "CURRENCY_RE = re.compile(r'[$£€¥]|usd|aud|gbp|cad', re.I)\n",
    "URL_EMAIL_RE = re.compile(r'http[s]?://|www\\.|@', re.I)\n",
    "PUNCT_Q = re.compile(r'\\?')\n",
    "\n",
    "def engineered_array(sent_list):\n",
    "    rows=[]\n",
    "    for s in sent_list:\n",
    "        sl = s.lower()\n",
    "        tokens = sl.split()\n",
    "        tc = max(1, len(tokens))\n",
    "        num_digits = 1 if NUM_RE.search(sl) else 0\n",
    "        has_weekday = 1 if WEEKDAY_RE.search(sl) else 0\n",
    "        has_month = 1 if MONTH_RE.search(sl) else 0\n",
    "        has_time = 1 if TIME_RE.search(sl) else 0\n",
    "        has_relative = 1 if RELATIVE_RE.search(sl) else 0\n",
    "        has_question = 1 if QUESTION_RE.search(sl) else 0\n",
    "        starts_imp = 1 if IMPERATIVE_RE.match(sl) else 0\n",
    "        has_duration = 1 if DURATION_RE.search(sl) else 0\n",
    "        has_currency = 1 if CURRENCY_RE.search(sl) else 0\n",
    "        has_url_email = 1 if URL_EMAIL_RE.search(sl) else 0\n",
    "        q_marks = len(PUNCT_Q.findall(sl))\n",
    "        avg_token_len = float(sum(len(t) for t in tokens) / tc)\n",
    "        unique_ratio = float(len(set(tokens)) / tc)\n",
    "        numeric_ratio = float(sum(1 for t in tokens if NUM_RE.fullmatch(t)) / tc)\n",
    "        rows.append([\n",
    "            tc, avg_token_len, unique_ratio, numeric_ratio,\n",
    "            num_digits, has_weekday, has_month, has_time, has_relative, has_duration,\n",
    "            has_question, starts_imp, has_currency, has_url_email, q_marks\n",
    "        ])\n",
    "    return np.array(rows, dtype=float)\n",
    "\n",
    "print(\"Extracting engineered features...\")\n",
    "X_eng = engineered_array(sentences)\n",
    "X_eng_sparse = csr_matrix(X_eng)\n",
    "\n",
    "# combine sparse parts\n",
    "parts = [X_word]\n",
    "if USE_CHAR and X_char is not None:\n",
    "    parts.append(X_char)\n",
    "parts.append(X_cue)\n",
    "parts.append(X_eng_sparse)\n",
    "X_all = hstack(parts, format='csr')\n",
    "print(\"Final combined X_all shape:\", X_all.shape)\n",
    "\n",
    "# save artifacts\n",
    "joblib.dump(tfidf_word, MODELS_DIR / \"tfidf_word_adj.joblib\", compress=3)\n",
    "if USE_CHAR and X_char is not None:\n",
    "    joblib.dump(tfidf_char, MODELS_DIR / \"tfidf_char_adj.joblib\", compress=3)\n",
    "joblib.dump(cue_vec, MODELS_DIR / \"cue_vec_adj.joblib\", compress=3)\n",
    "meta = {\n",
    "    'created': datetime.now().isoformat(),\n",
    "    'n_examples': n,\n",
    "    'word_max_features': WORD_MAX_FEATURES,\n",
    "    'char_max_features': CHAR_MAX_FEATURES if USE_CHAR else 0,\n",
    "    'engineered_feature_count': X_eng.shape[1],\n",
    "    'engineered_feature_names': [\n",
    "        'token_count','avg_token_len','unique_ratio','numeric_ratio',\n",
    "        'has_digit','has_weekday','has_month','has_time','has_relative','has_duration',\n",
    "        'has_question','starts_imperative','has_currency','has_url_email','q_marks'\n",
    "    ]\n",
    "}\n",
    "with open(MODELS_DIR / \"feature_metadata_adj.json\", \"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump(meta, fh, indent=2)\n",
    "\n",
    "print(\"Saved adjusted vectorizers & metadata. X_all ready for training.\")\n",
    "# expose X_all, labels\n",
    "X_all, labels = X_all, np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a772442-e408-458f-9036-c225f15fdc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Calib/Test sizes: 660820 82603 82603\n",
      "Training LinearSVC (GridSearchCV with cv=3)...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tar_guest/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/tar_guest/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/tar_guest/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/tar_guest/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/tar_guest/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/tar_guest/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC trained. Best params: {'C': 1.0}\n",
      "Calibrating (prefit) on calibration set...\n",
      "Calibrator saved.\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    deadline     0.9979    1.0000    0.9989       945\n",
      "    question     0.9986    0.9991    0.9988     80659\n",
      "        task     0.9236    0.8829    0.9028       999\n",
      "\n",
      "    accuracy                         0.9977     82603\n",
      "   macro avg     0.9733    0.9607    0.9668     82603\n",
      "weighted avg     0.9976    0.9977    0.9977     82603\n",
      "\n",
      "Macro-F1: 0.9668388645008551\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENT: when was princess calla born\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: hurst definition\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what is degree of licenses and science?\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what does anti money laundering mean\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: how much does rgis pay\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what is euploidy and aneuploidy\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what is a pom in development\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: how network security\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 0.9999, 'task': 0.0001}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what is the difference between acrylic and enamel automotive paint?\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: most lethal venom in the world\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: is testosterone a protein\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 0.9999, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: is easy to use hyphenated?\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what is the basic unit of measurement in the metric system?\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: diwali tickets\n",
      " PRED: task  TRUE: task  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 0.021, 'task': 0.979}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what county is two buttes colorado\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: is obsidian formed underground\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 0.9999, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: where can i buy a 55 gallon drum\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: where do lake trout spawn on lake superior\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: is your child too sick for school children's healthcare\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "SENT: what is on premise pertaining to alcohol\n",
      " PRED: question  TRUE: question  FLAG_POSSIBLE_DEADLINE? False\n",
      " PROBS: {'deadline': 0.0, 'question': 1.0, 'task': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "Training complete. Artifacts saved to models/.\n"
     ]
    }
   ],
   "source": [
    "# STEP 4 (ADJUSTED): train LinearSVC on train set; calibrate (prefit) on a smaller calibration set; fallback to SGD if SVC OOMs.\n",
    "import numpy as np, joblib, json, traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "OUT = Path(\"models\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# options tuned to be practical\n",
    "CALIBRATE = True\n",
    "TEST_SIZE = 0.10\n",
    "CALIB_SIZE = 0.10   # calibration set size (of whole)\n",
    "RND = 42\n",
    "C_GRID = [0.1, 1.0]  # small grid\n",
    "CV_FOLDS = 3\n",
    "\n",
    "assert 'X_all' in globals() and 'labels' in globals(), \"Run STEP 3 adjusted first.\"\n",
    "\n",
    "y = np.array(labels)\n",
    "idx = np.arange(X_all.shape[0])\n",
    "train_idx, temp_idx, y_train, y_temp = train_test_split(idx, y, test_size=(TEST_SIZE + CALIB_SIZE), stratify=y, random_state=RND)\n",
    "calib_frac_of_temp = CALIB_SIZE / (TEST_SIZE + CALIB_SIZE)\n",
    "calib_idx, test_idx, y_calib, y_test = train_test_split(temp_idx, y_temp, test_size=(1-calib_frac_of_temp), stratify=y_temp, random_state=RND)\n",
    "\n",
    "print(\"Train/Calib/Test sizes:\", len(train_idx), len(calib_idx), len(test_idx))\n",
    "\n",
    "X_train = X_all[train_idx]\n",
    "X_calib  = X_all[calib_idx]\n",
    "X_test   = X_all[test_idx]\n",
    "\n",
    "svc_model = None\n",
    "calibrator = None\n",
    "trained_with = None\n",
    "\n",
    "try:\n",
    "    print(\"Training LinearSVC (GridSearchCV with cv=%d)...\" % CV_FOLDS)\n",
    "    svc = LinearSVC(class_weight='balanced', max_iter=20000)\n",
    "    grid = GridSearchCV(svc, {'C': C_GRID}, scoring='f1_macro', cv=CV_FOLDS, n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    svc_model = grid.best_estimator_\n",
    "    trained_with = 'svc'\n",
    "    joblib.dump(svc_model, OUT / \"svc_adj.joblib\", compress=3)\n",
    "    print(\"SVC trained. Best params:\", grid.best_params_)\n",
    "    # calibrate if requested\n",
    "    if CALIBRATE:\n",
    "        print(\"Calibrating (prefit) on calibration set...\")\n",
    "        calibrator = CalibratedClassifierCV(svc_model, method='sigmoid', cv='prefit')\n",
    "        calibrator.fit(X_calib, y_calib)\n",
    "        joblib.dump(calibrator, OUT / \"svc_calibrated_adj.joblib\", compress=3)\n",
    "        print(\"Calibrator saved.\")\n",
    "except Exception as e:\n",
    "    print(\"SVC failed or OOM. Falling back to SGD partial_fit. Exception:\")\n",
    "    traceback.print_exc()\n",
    "    trained_with = 'sgd'\n",
    "    # incremental SGD training over shuffled data\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    classes = np.unique(y)\n",
    "    sgd = SGDClassifier(loss='hinge', class_weight='balanced', random_state=RND)\n",
    "    chunk_size = 50000  # reduce if still heavy\n",
    "    order = np.arange(X_all.shape[0])\n",
    "    np.random.seed(RND)\n",
    "    np.random.shuffle(order)\n",
    "    for start in range(0, X_all.shape[0], chunk_size):\n",
    "        batch_idx = order[start:start+chunk_size]\n",
    "        Xb = X_all[batch_idx]\n",
    "        yb = y[batch_idx]\n",
    "        if start == 0:\n",
    "            sgd.partial_fit(Xb, yb, classes=classes)\n",
    "        else:\n",
    "            sgd.partial_fit(Xb, yb)\n",
    "        print(\" Trained chunk\", start, \"->\", start+len(batch_idx))\n",
    "    svc_model = sgd\n",
    "    joblib.dump(svc_model, OUT / \"sgd_partial_adj.joblib\", compress=3)\n",
    "    print(\"SGD fallback model saved. Skipping calibration for fallback.\")\n",
    "\n",
    "# Evaluate\n",
    "if calibrator is not None:\n",
    "    y_pred = calibrator.predict(X_test)\n",
    "    y_proba = calibrator.predict_proba(X_test)\n",
    "else:\n",
    "    y_pred = svc_model.predict(X_test)\n",
    "    y_proba = None\n",
    "\n",
    "print(\"Classification report (test):\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"Macro-F1:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# confusion matrix\n",
    "labels_unique = sorted(np.unique(y))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels_unique)\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels_unique, yticklabels=labels_unique)\n",
    "plt.xlabel('predicted'); plt.ylabel('true'); plt.title('Confusion matrix (test)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"confusion_adj.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# show some sample predictions with confidences (if available) and the task->deadline check\n",
    "import random, re\n",
    "WEEKDAY_RE = re.compile(r'\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b', re.I)\n",
    "MONTH_RE = re.compile(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b', re.I)\n",
    "TIME_RE = re.compile(r'\\b(?:\\d{1,2}(:\\d{2})?\\s*(am|pm)|am|pm|noon|midnight|eod|cob)\\b', re.I)\n",
    "RELATIVE_RE = re.compile(r'\\b(tomorrow|today|next|in\\s+\\d+\\s+(?:day|days|week|weeks|month|months|hour|hours|minute|minutes))\\b', re.I)\n",
    "NUM_RE = re.compile(r'\\d+')\n",
    "\n",
    "def has_date_like(s):\n",
    "    sl = s.lower()\n",
    "    return bool(WEEKDAY_RE.search(sl) or MONTH_RE.search(sl) or TIME_RE.search(sl) or RELATIVE_RE.search(sl) or NUM_RE.search(sl))\n",
    "\n",
    "rnd = random.Random(RND)\n",
    "sample_test_idx = rnd.sample(list(test_idx), min(20, len(test_idx)))\n",
    "for idx0 in sample_test_idx:\n",
    "    sent_orig = df.iloc[idx0]['sentence_orig'] if 'sentence_orig' in df.columns else df.iloc[idx0]['sentence']\n",
    "    sent_norm = df.iloc[idx0]['sentence']\n",
    "    true_label = df.iloc[idx0]['label']\n",
    "    if y_proba is not None:\n",
    "        proba = calibrator.predict_proba(X_all[idx0])\n",
    "        probs = dict(zip(calibrator.classes_.tolist(), proba.flatten().round(4).tolist()))\n",
    "        pred_label = max(probs.items(), key=lambda x: x[1])[0]\n",
    "    else:\n",
    "        pred_label = svc_model.predict(X_all[idx0])[0]\n",
    "        probs = None\n",
    "    flag_dead = (pred_label=='task') and has_date_like(sent_norm)\n",
    "    print(\"SENT:\", sent_orig)\n",
    "    print(\" PRED:\", pred_label, \" TRUE:\", true_label, \" FLAG_POSSIBLE_DEADLINE?\", flag_dead)\n",
    "    if probs is not None:\n",
    "        print(\" PROBS:\", probs)\n",
    "    print(\"-\"*80)\n",
    "\n",
    "# save training manifest\n",
    "manifest = {\n",
    "    'trained_with': trained_with,\n",
    "    'calibrated': bool(calibrator is not None),\n",
    "    'created': datetime.now().isoformat()\n",
    "}\n",
    "with open(OUT / \"train_manifest_adj.json\", \"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump(manifest, fh, indent=2)\n",
    "\n",
    "print(\"Training complete. Artifacts saved to models/.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80d1b5c-9b89-418f-a978-f27fac2dfc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded combined df rows: 826026\n",
      "Loaded calibrated classifier: svc_calibrated_adj.joblib\n",
      "Using test set size: 82603\n",
      "\n",
      "Classification report (test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    deadline     0.9979    1.0000    0.9989       945\n",
      "    question     0.9986    0.9991    0.9988     80659\n",
      "        task     0.9236    0.8829    0.9028       999\n",
      "\n",
      "    accuracy                         0.9977     82603\n",
      "   macro avg     0.9733    0.9607    0.9668     82603\n",
      "weighted avg     0.9976    0.9977    0.9977     82603\n",
      "\n",
      "Confusion matrix labels: ['deadline', 'question', 'task']\n",
      "[[  945     0     0]\n",
      " [    2 80584    73]\n",
      " [    0   117   882]]\n",
      "\n",
      "Task false negatives (true=task but pred!=task): 117\n",
      "Task false positives (pred=task but true!=task): 73\n",
      "Saved FN examples -> models/task_false_negatives.csv\n",
      "Saved FP examples -> models/task_false_positives.csv\n",
      "\n",
      "Task FALSE NEGATIVES (showing up to 40 examples):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>label_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27394</th>\n",
       "      <td>deepika cider vinegar</td>\n",
       "      <td>deepika cider vinegar</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>food handler card</td>\n",
       "      <td>food handler card</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34616</th>\n",
       "      <td>garlic oil</td>\n",
       "      <td>garlic oil</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25630</th>\n",
       "      <td>make chrome default browser</td>\n",
       "      <td>make chrome default browser</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>language test</td>\n",
       "      <td>language test</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56799</th>\n",
       "      <td>pharmacademic</td>\n",
       "      <td>pharmacademic</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48487</th>\n",
       "      <td>recite holy quran</td>\n",
       "      <td>recite holy quran</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64412</th>\n",
       "      <td>razors</td>\n",
       "      <td>razors</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24153</th>\n",
       "      <td>whole wheat spiral pasta</td>\n",
       "      <td>whole wheat spiral pasta</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>buy curtains and curtain rod</td>\n",
       "      <td>buy curtains and curtain rod</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24856</th>\n",
       "      <td>buy gift for secret santa</td>\n",
       "      <td>buy gift for secret santa</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17490</th>\n",
       "      <td>barclays debit card</td>\n",
       "      <td>barclays debit card</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65626</th>\n",
       "      <td>phylogenetic tree</td>\n",
       "      <td>phylogenetic tree</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72994</th>\n",
       "      <td>respond to all text messages</td>\n",
       "      <td>respond to all text messages</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15353</th>\n",
       "      <td>install carbon monoxide detector</td>\n",
       "      <td>install carbon monoxide detector</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>canadian passports</td>\n",
       "      <td>canadian passports</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39341</th>\n",
       "      <td>roaming options</td>\n",
       "      <td>roaming options</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76575</th>\n",
       "      <td>schedule matrix</td>\n",
       "      <td>schedule matrix</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51609</th>\n",
       "      <td>european wax</td>\n",
       "      <td>european wax</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68846</th>\n",
       "      <td>kpi scorecard</td>\n",
       "      <td>kpi scorecard</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45445</th>\n",
       "      <td>congratulations email</td>\n",
       "      <td>congratulations email</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59574</th>\n",
       "      <td>make an instagram post</td>\n",
       "      <td>make an instagram post</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80842</th>\n",
       "      <td>check on global entry status</td>\n",
       "      <td>check on global entry status</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>isao cider vinegar</td>\n",
       "      <td>isao cider vinegar</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>advisor agreements</td>\n",
       "      <td>advisor agreements</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46128</th>\n",
       "      <td>statement of purpose</td>\n",
       "      <td>statement of purpose</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19649</th>\n",
       "      <td>edit articles</td>\n",
       "      <td>edit articles</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16957</th>\n",
       "      <td>bake scones</td>\n",
       "      <td>bake scones</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36357</th>\n",
       "      <td>uv film</td>\n",
       "      <td>uv film</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16493</th>\n",
       "      <td>bankruptcy payment</td>\n",
       "      <td>bankruptcy payment</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76021</th>\n",
       "      <td>nutcracker movie</td>\n",
       "      <td>nutcracker movie</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41781</th>\n",
       "      <td>member benefits</td>\n",
       "      <td>member benefits</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>actors access</td>\n",
       "      <td>actors access</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19152</th>\n",
       "      <td>install momentum chrome extension</td>\n",
       "      <td>install momentum chrome extension</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49831</th>\n",
       "      <td>transfer vhs to dvd</td>\n",
       "      <td>transfer vhs to dvd</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28883</th>\n",
       "      <td>pirate booty</td>\n",
       "      <td>pirate booty</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>texture gun</td>\n",
       "      <td>texture gun</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19862</th>\n",
       "      <td>dissertation edits</td>\n",
       "      <td>dissertation edits</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75525</th>\n",
       "      <td>good meal</td>\n",
       "      <td>good meal</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44052</th>\n",
       "      <td>exhibitor badges</td>\n",
       "      <td>exhibitor badges</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "      <td>mslatte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           sentence_orig                           sentence  \\\n",
       "27394              deepika cider vinegar              deepika cider vinegar   \n",
       "2283                   food handler card                  food handler card   \n",
       "34616                         garlic oil                         garlic oil   \n",
       "25630        make chrome default browser        make chrome default browser   \n",
       "6132                       language test                      language test   \n",
       "56799                      pharmacademic                      pharmacademic   \n",
       "48487                  recite holy quran                  recite holy quran   \n",
       "64412                             razors                             razors   \n",
       "24153           whole wheat spiral pasta           whole wheat spiral pasta   \n",
       "7953        buy curtains and curtain rod       buy curtains and curtain rod   \n",
       "24856          buy gift for secret santa          buy gift for secret santa   \n",
       "17490                barclays debit card                barclays debit card   \n",
       "65626                  phylogenetic tree                  phylogenetic tree   \n",
       "72994       respond to all text messages       respond to all text messages   \n",
       "15353   install carbon monoxide detector   install carbon monoxide detector   \n",
       "990                   canadian passports                 canadian passports   \n",
       "39341                    roaming options                    roaming options   \n",
       "76575                    schedule matrix                    schedule matrix   \n",
       "51609                       european wax                       european wax   \n",
       "68846                      kpi scorecard                      kpi scorecard   \n",
       "45445              congratulations email              congratulations email   \n",
       "59574             make an instagram post             make an instagram post   \n",
       "80842       check on global entry status       check on global entry status   \n",
       "7995                  isao cider vinegar                 isao cider vinegar   \n",
       "10678                 advisor agreements                 advisor agreements   \n",
       "46128               statement of purpose               statement of purpose   \n",
       "19649                      edit articles                      edit articles   \n",
       "16957                        bake scones                        bake scones   \n",
       "36357                            uv film                            uv film   \n",
       "16493                 bankruptcy payment                 bankruptcy payment   \n",
       "76021                   nutcracker movie                   nutcracker movie   \n",
       "41781                    member benefits                    member benefits   \n",
       "54199                      actors access                      actors access   \n",
       "19152  install momentum chrome extension  install momentum chrome extension   \n",
       "49831                transfer vhs to dvd                transfer vhs to dvd   \n",
       "28883                       pirate booty                       pirate booty   \n",
       "5476                         texture gun                        texture gun   \n",
       "19862                 dissertation edits                 dissertation edits   \n",
       "75525                          good meal                          good meal   \n",
       "44052                   exhibitor badges                   exhibitor badges   \n",
       "\n",
       "       true      pred label_source  \n",
       "27394  task  question      mslatte  \n",
       "2283   task  question      mslatte  \n",
       "34616  task  question      mslatte  \n",
       "25630  task  question      mslatte  \n",
       "6132   task  question      mslatte  \n",
       "56799  task  question      mslatte  \n",
       "48487  task  question      mslatte  \n",
       "64412  task  question      mslatte  \n",
       "24153  task  question      mslatte  \n",
       "7953   task  question      mslatte  \n",
       "24856  task  question      mslatte  \n",
       "17490  task  question      mslatte  \n",
       "65626  task  question      mslatte  \n",
       "72994  task  question      mslatte  \n",
       "15353  task  question      mslatte  \n",
       "990    task  question      mslatte  \n",
       "39341  task  question      mslatte  \n",
       "76575  task  question      mslatte  \n",
       "51609  task  question      mslatte  \n",
       "68846  task  question      mslatte  \n",
       "45445  task  question      mslatte  \n",
       "59574  task  question      mslatte  \n",
       "80842  task  question      mslatte  \n",
       "7995   task  question      mslatte  \n",
       "10678  task  question      mslatte  \n",
       "46128  task  question      mslatte  \n",
       "19649  task  question      mslatte  \n",
       "16957  task  question      mslatte  \n",
       "36357  task  question      mslatte  \n",
       "16493  task  question      mslatte  \n",
       "76021  task  question      mslatte  \n",
       "41781  task  question      mslatte  \n",
       "54199  task  question      mslatte  \n",
       "19152  task  question      mslatte  \n",
       "49831  task  question      mslatte  \n",
       "28883  task  question      mslatte  \n",
       "5476   task  question      mslatte  \n",
       "19862  task  question      mslatte  \n",
       "75525  task  question      mslatte  \n",
       "44052  task  question      mslatte  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task FALSE POSITIVES (showing up to 40 examples):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "      <th>label_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>pay credit card costco</td>\n",
       "      <td>pay credit card costco</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76351</th>\n",
       "      <td>amcpx dividends</td>\n",
       "      <td>amcpx dividends</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>feet cracked</td>\n",
       "      <td>feet cracked</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>reduce morning eye redness</td>\n",
       "      <td>reduce morning eye redness</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32509</th>\n",
       "      <td>internet fax</td>\n",
       "      <td>internet fax</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81897</th>\n",
       "      <td>pay for speeding ticket</td>\n",
       "      <td>pay for speeding ticket</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>tryptophan turns into</td>\n",
       "      <td>tryptophan turns into</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39514</th>\n",
       "      <td>pa dmv contact</td>\n",
       "      <td>pa dmv contact</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256</th>\n",
       "      <td>the donut store</td>\n",
       "      <td>the donut store</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66321</th>\n",
       "      <td>cgview server</td>\n",
       "      <td>cgview server</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78095</th>\n",
       "      <td>photoshop add mask to layer</td>\n",
       "      <td>photoshop add mask to layer</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34175</th>\n",
       "      <td>reseller's permit</td>\n",
       "      <td>reseller's permit</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10168</th>\n",
       "      <td>copy stand</td>\n",
       "      <td>copy stand</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53281</th>\n",
       "      <td>anytime laundry</td>\n",
       "      <td>anytime laundry</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>skype powershell</td>\n",
       "      <td>skype powershell</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24486</th>\n",
       "      <td>ups box requirements</td>\n",
       "      <td>ups box requirements</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67613</th>\n",
       "      <td>jp printer</td>\n",
       "      <td>jp printer</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58028</th>\n",
       "      <td>tsa precheck appointment</td>\n",
       "      <td>tsa precheck appointment</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36216</th>\n",
       "      <td>118.5/2</td>\n",
       "      <td>118.5/2</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47459</th>\n",
       "      <td>army baq pay</td>\n",
       "      <td>army baq pay</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80028</th>\n",
       "      <td>hourly forms</td>\n",
       "      <td>hourly forms</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17814</th>\n",
       "      <td>hatake clan</td>\n",
       "      <td>hatake clan</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40190</th>\n",
       "      <td>bonding primer</td>\n",
       "      <td>bonding primer</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53189</th>\n",
       "      <td>thicken my soup</td>\n",
       "      <td>thicken my soup</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74366</th>\n",
       "      <td>callie cobra</td>\n",
       "      <td>callie cobra</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8343</th>\n",
       "      <td>zinc ointment</td>\n",
       "      <td>zinc ointment</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67326</th>\n",
       "      <td>sweet gasoline</td>\n",
       "      <td>sweet gasoline</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51657</th>\n",
       "      <td>tire tax form</td>\n",
       "      <td>tire tax form</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33266</th>\n",
       "      <td>weeks act</td>\n",
       "      <td>weeks act</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54856</th>\n",
       "      <td>ga driving test tips</td>\n",
       "      <td>ga driving test tips</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56405</th>\n",
       "      <td>balance squats</td>\n",
       "      <td>balance squats</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23054</th>\n",
       "      <td>ibuprofen plus</td>\n",
       "      <td>ibuprofen plus</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70540</th>\n",
       "      <td>bridges exercises</td>\n",
       "      <td>bridges exercises</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26199</th>\n",
       "      <td>benefits documentation advisory</td>\n",
       "      <td>benefits documentation advisory</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48242</th>\n",
       "      <td>chinese goose</td>\n",
       "      <td>chinese goose</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12796</th>\n",
       "      <td>seasons calendar</td>\n",
       "      <td>seasons calendar</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63055</th>\n",
       "      <td>fold up steps</td>\n",
       "      <td>fold up steps</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>earth day shirt</td>\n",
       "      <td>earth day shirt</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19709</th>\n",
       "      <td>dog car/booster seat</td>\n",
       "      <td>dog car/booster seat</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42820</th>\n",
       "      <td>forms of algae</td>\n",
       "      <td>forms of algae</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "      <td>msmarco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sentence_orig                         sentence  \\\n",
       "2996            pay credit card costco           pay credit card costco   \n",
       "76351                  amcpx dividends                  amcpx dividends   \n",
       "21581                     feet cracked                     feet cracked   \n",
       "1323        reduce morning eye redness       reduce morning eye redness   \n",
       "32509                     internet fax                     internet fax   \n",
       "81897          pay for speeding ticket          pay for speeding ticket   \n",
       "11320            tryptophan turns into            tryptophan turns into   \n",
       "39514                   pa dmv contact                   pa dmv contact   \n",
       "12256                  the donut store                  the donut store   \n",
       "66321                    cgview server                    cgview server   \n",
       "78095      photoshop add mask to layer      photoshop add mask to layer   \n",
       "34175                reseller's permit                reseller's permit   \n",
       "10168                       copy stand                       copy stand   \n",
       "53281                  anytime laundry                  anytime laundry   \n",
       "7595                  skype powershell                 skype powershell   \n",
       "24486             ups box requirements             ups box requirements   \n",
       "67613                       jp printer                       jp printer   \n",
       "58028         tsa precheck appointment         tsa precheck appointment   \n",
       "36216                          118.5/2                          118.5/2   \n",
       "47459                     army baq pay                     army baq pay   \n",
       "80028                     hourly forms                     hourly forms   \n",
       "17814                      hatake clan                      hatake clan   \n",
       "40190                   bonding primer                   bonding primer   \n",
       "53189                  thicken my soup                  thicken my soup   \n",
       "74366                     callie cobra                     callie cobra   \n",
       "8343                     zinc ointment                    zinc ointment   \n",
       "67326                   sweet gasoline                   sweet gasoline   \n",
       "51657                    tire tax form                    tire tax form   \n",
       "33266                        weeks act                        weeks act   \n",
       "54856             ga driving test tips             ga driving test tips   \n",
       "56405                   balance squats                   balance squats   \n",
       "23054                   ibuprofen plus                   ibuprofen plus   \n",
       "70540                bridges exercises                bridges exercises   \n",
       "26199  benefits documentation advisory  benefits documentation advisory   \n",
       "48242                    chinese goose                    chinese goose   \n",
       "12796                 seasons calendar                 seasons calendar   \n",
       "63055                    fold up steps                    fold up steps   \n",
       "2249                   earth day shirt                  earth day shirt   \n",
       "19709             dog car/booster seat             dog car/booster seat   \n",
       "42820                   forms of algae                   forms of algae   \n",
       "\n",
       "           true  pred label_source  \n",
       "2996   question  task      msmarco  \n",
       "76351  question  task      msmarco  \n",
       "21581  question  task      msmarco  \n",
       "1323   question  task      msmarco  \n",
       "32509  question  task      msmarco  \n",
       "81897  question  task      msmarco  \n",
       "11320  question  task      msmarco  \n",
       "39514  question  task      msmarco  \n",
       "12256  question  task      msmarco  \n",
       "66321  question  task      msmarco  \n",
       "78095  question  task      msmarco  \n",
       "34175  question  task      msmarco  \n",
       "10168  question  task      msmarco  \n",
       "53281  question  task      msmarco  \n",
       "7595   question  task      msmarco  \n",
       "24486  question  task      msmarco  \n",
       "67613  question  task      msmarco  \n",
       "58028  question  task      msmarco  \n",
       "36216  question  task      msmarco  \n",
       "47459  question  task      msmarco  \n",
       "80028  question  task      msmarco  \n",
       "17814  question  task      msmarco  \n",
       "40190  question  task      msmarco  \n",
       "53189  question  task      msmarco  \n",
       "74366  question  task      msmarco  \n",
       "8343   question  task      msmarco  \n",
       "67326  question  task      msmarco  \n",
       "51657  question  task      msmarco  \n",
       "33266  question  task      msmarco  \n",
       "54856  question  task      msmarco  \n",
       "56405  question  task      msmarco  \n",
       "23054  question  task      msmarco  \n",
       "70540  question  task      msmarco  \n",
       "26199  question  task      msmarco  \n",
       "48242  question  task      msmarco  \n",
       "12796  question  task      msmarco  \n",
       "63055  question  task      msmarco  \n",
       "2249   question  task      msmarco  \n",
       "19709  question  task      msmarco  \n",
       "42820  question  task      msmarco  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top tokens in Task FALSE NEGATIVES:\n",
      "[('to', 7), ('of', 6), ('change', 4), ('do', 3), ('card', 3), ('buy', 3), ('and', 3), ('on', 3), ('make', 3), ('cider', 2), ('vinegar', 2), ('install', 2), ('carbon', 2), ('monoxide', 2), ('amazon', 2), ('barclays', 2), ('debit', 2), ('address', 2), ('chrome', 2), ('for', 2), ('in', 2), ('detectors', 2), ('dishes', 2), ('dishwasher', 2), ('schedule', 2), ('exercises', 2), ('the', 2), ('system', 2), ('take', 2), ('canadian', 1)]\n",
      "\n",
      "Top tokens in Task FALSE POSITIVES:\n",
      "[('pay', 5), ('for', 4), ('test', 3), ('accounting', 2), ('insurance', 2), ('in', 2), ('a', 2), ('stand', 2), ('the', 2), ('tsa', 2), ('payment', 2), ('forms', 2), ('of', 2), ('reduce', 1), ('morning', 1), ('eye', 1), ('redness', 1), ('cover', 1), ('letter', 1), ('crm', 1), ('earth', 1), ('day', 1), ('shirt', 1), ('credit', 1), ('card', 1), ('costco', 1), ('skype', 1), ('powershell', 1), ('hat', 1), ('bag', 1)]\n",
      "\n",
      "False negatives with date-like tokens: 2 / 117\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65816</th>\n",
       "      <td>next weeks menu</td>\n",
       "      <td>next weeks menu</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55050</th>\n",
       "      <td>18 min cardio</td>\n",
       "      <td>18 min cardio</td>\n",
       "      <td>task</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentence_orig         sentence  true      pred\n",
       "65816  next weeks menu  next weeks menu  task  question\n",
       "55050    18 min cardio    18 min cardio  task  question"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FP class distribution (what true classes were predicted as task?):\n",
      "{'question': 73}\n",
      "FPs containing date-like tokens: 3 / 73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>pay credit card costco</td>\n",
       "      <td>pay credit card costco</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76351</th>\n",
       "      <td>amcpx dividends</td>\n",
       "      <td>amcpx dividends</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21581</th>\n",
       "      <td>feet cracked</td>\n",
       "      <td>feet cracked</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>reduce morning eye redness</td>\n",
       "      <td>reduce morning eye redness</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32509</th>\n",
       "      <td>internet fax</td>\n",
       "      <td>internet fax</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81897</th>\n",
       "      <td>pay for speeding ticket</td>\n",
       "      <td>pay for speeding ticket</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11320</th>\n",
       "      <td>tryptophan turns into</td>\n",
       "      <td>tryptophan turns into</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39514</th>\n",
       "      <td>pa dmv contact</td>\n",
       "      <td>pa dmv contact</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12256</th>\n",
       "      <td>the donut store</td>\n",
       "      <td>the donut store</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66321</th>\n",
       "      <td>cgview server</td>\n",
       "      <td>cgview server</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78095</th>\n",
       "      <td>photoshop add mask to layer</td>\n",
       "      <td>photoshop add mask to layer</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34175</th>\n",
       "      <td>reseller's permit</td>\n",
       "      <td>reseller's permit</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10168</th>\n",
       "      <td>copy stand</td>\n",
       "      <td>copy stand</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53281</th>\n",
       "      <td>anytime laundry</td>\n",
       "      <td>anytime laundry</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>skype powershell</td>\n",
       "      <td>skype powershell</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24486</th>\n",
       "      <td>ups box requirements</td>\n",
       "      <td>ups box requirements</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67613</th>\n",
       "      <td>jp printer</td>\n",
       "      <td>jp printer</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58028</th>\n",
       "      <td>tsa precheck appointment</td>\n",
       "      <td>tsa precheck appointment</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36216</th>\n",
       "      <td>118.5/2</td>\n",
       "      <td>118.5/2</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47459</th>\n",
       "      <td>army baq pay</td>\n",
       "      <td>army baq pay</td>\n",
       "      <td>question</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sentence_orig                     sentence      true  \\\n",
       "2996        pay credit card costco       pay credit card costco  question   \n",
       "76351              amcpx dividends              amcpx dividends  question   \n",
       "21581                 feet cracked                 feet cracked  question   \n",
       "1323    reduce morning eye redness   reduce morning eye redness  question   \n",
       "32509                 internet fax                 internet fax  question   \n",
       "81897      pay for speeding ticket      pay for speeding ticket  question   \n",
       "11320        tryptophan turns into        tryptophan turns into  question   \n",
       "39514               pa dmv contact               pa dmv contact  question   \n",
       "12256              the donut store              the donut store  question   \n",
       "66321                cgview server                cgview server  question   \n",
       "78095  photoshop add mask to layer  photoshop add mask to layer  question   \n",
       "34175            reseller's permit            reseller's permit  question   \n",
       "10168                   copy stand                   copy stand  question   \n",
       "53281              anytime laundry              anytime laundry  question   \n",
       "7595              skype powershell             skype powershell  question   \n",
       "24486         ups box requirements         ups box requirements  question   \n",
       "67613                   jp printer                   jp printer  question   \n",
       "58028     tsa precheck appointment     tsa precheck appointment  question   \n",
       "36216                      118.5/2                      118.5/2  question   \n",
       "47459                 army baq pay                 army baq pay  question   \n",
       "\n",
       "       pred  \n",
       "2996   task  \n",
       "76351  task  \n",
       "21581  task  \n",
       "1323   task  \n",
       "32509  task  \n",
       "81897  task  \n",
       "11320  task  \n",
       "39514  task  \n",
       "12256  task  \n",
       "66321  task  \n",
       "78095  task  \n",
       "34175  task  \n",
       "10168  task  \n",
       "53281  task  \n",
       "7595   task  \n",
       "24486  task  \n",
       "67613  task  \n",
       "58028  task  \n",
       "36216  task  \n",
       "47459  task  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to show top feature tokens for 'task' class (if vectorizers available)...\n",
      "Could not show detailed feature tokens (missing vectorizers/metadata or mismatch). Error: 'CalibratedClassifierCV' object has no attribute 'base_estimator'\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Targeted error analysis for the 'task' class (run after Step 4)\n",
    "import joblib, json, re, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import Counter\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "OUT_FN_CSV = MODELS_DIR / \"task_false_negatives.csv\"\n",
    "OUT_FP_CSV = MODELS_DIR / \"task_false_positives.csv\"\n",
    "\n",
    "# load combined df\n",
    "DF_PATH = Path(\"data/processed/combined_dataset.csv\")\n",
    "df = pd.read_csv(DF_PATH, dtype=str, keep_default_na=False)\n",
    "n = len(df)\n",
    "print(\"Loaded combined df rows:\", n)\n",
    "\n",
    "try:\n",
    "    X_all  # noqa: F821\n",
    "    labels  # noqa: F821\n",
    "except NameError:\n",
    "    raise RuntimeError(\"X_all and labels not found in notebook. Re-run Step 3 adjusted to produce X_all and labels in the notebook namespace.\")\n",
    "\n",
    "cal = None\n",
    "svc = None\n",
    "if (MODELS_DIR / \"svc_calibrated_adj.joblib\").exists():\n",
    "    try:\n",
    "        cal = joblib.load(MODELS_DIR / \"svc_calibrated_adj.joblib\")\n",
    "        print(\"Loaded calibrated classifier:\", \"svc_calibrated_adj.joblib\")\n",
    "    except Exception:\n",
    "        cal = None\n",
    "if cal is None and (MODELS_DIR / \"svc_adj.joblib\").exists():\n",
    "    svc = joblib.load(MODELS_DIR / \"svc_adj.joblib\")\n",
    "    print(\"Loaded SVC (no calibrator): svc_adj.joblib\")\n",
    "elif cal is None and svc is None:\n",
    "    # try other names\n",
    "    if (MODELS_DIR / \"svc_trained_on_train.joblib\").exists():\n",
    "        svc = joblib.load(MODELS_DIR / \"svc_trained_on_train.joblib\")\n",
    "        print(\"Loaded SVC svc_trained_on_train.joblib\")\n",
    "\n",
    "RND = 42\n",
    "TEST_SIZE = 0.10\n",
    "CALIB_SIZE = 0.10\n",
    "y = np.array(labels)\n",
    "idx = np.arange(len(y))\n",
    "train_idx, temp_idx, _, _ = train_test_split(idx, y, test_size=(TEST_SIZE + CALIB_SIZE), stratify=y, random_state=RND)\n",
    "calib_frac_of_temp = CALIB_SIZE / (TEST_SIZE + CALIB_SIZE)\n",
    "calib_idx, test_idx, _, _ = train_test_split(temp_idx, y[temp_idx], test_size=(1-calib_frac_of_temp), stratify=y[temp_idx], random_state=RND)\n",
    "\n",
    "print(\"Using test set size:\", len(test_idx))\n",
    "\n",
    "# Predict on test set\n",
    "if cal is not None:\n",
    "    y_pred = cal.predict(X_all[test_idx])\n",
    "    try:\n",
    "        y_proba = cal.predict_proba(X_all[test_idx])\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "else:\n",
    "    y_pred = svc.predict(X_all[test_idx])\n",
    "    y_proba = None\n",
    "\n",
    "y_true = y[test_idx]\n",
    "\n",
    "# Basic metrics & confusion\n",
    "print(\"\\nClassification report (test):\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "labels_unique = sorted(list(set(y)))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_unique)\n",
    "print(\"Confusion matrix labels:\", labels_unique)\n",
    "print(cm)\n",
    "\n",
    "test_df = df.iloc[test_idx].copy().reset_index(drop=True)\n",
    "test_df['true'] = y_true\n",
    "test_df['pred'] = y_pred\n",
    "\n",
    "fn = test_df[(test_df['true']=='task') & (test_df['pred']!='task')].copy()\n",
    "fp = test_df[(test_df['pred']=='task') & (test_df['true']!='task')].copy()\n",
    "print(f\"\\nTask false negatives (true=task but pred!=task): {len(fn)}\")\n",
    "print(f\"Task false positives (pred=task but true!=task): {len(fp)}\")\n",
    "\n",
    "# Save CSVs for manual inspection\n",
    "fn.to_csv(OUT_FN_CSV, index=False, encoding='utf8')\n",
    "fp.to_csv(OUT_FP_CSV, index=False, encoding='utf8')\n",
    "print(f\"Saved FN examples -> {OUT_FN_CSV}\")\n",
    "print(f\"Saved FP examples -> {OUT_FP_CSV}\")\n",
    "\n",
    "# Show representative samples (up to 40 each)\n",
    "def show_sample(df_sub, n=20, title=\"Samples\"):\n",
    "    print(f\"\\n{title} (showing up to {n} examples):\")\n",
    "    display(df_sub[['sentence_orig','sentence','true','pred','label_source']].head(n))\n",
    "\n",
    "show_sample(fn.sample(min(40, len(fn)), random_state=RND) if len(fn)>0 else fn, n=40, title=\"Task FALSE NEGATIVES\")\n",
    "show_sample(fp.sample(min(40, len(fp)), random_state=RND) if len(fp)>0 else fp, n=40, title=\"Task FALSE POSITIVES\")\n",
    "\n",
    "def top_tokens(series, topk=30):\n",
    "    from collections import Counter\n",
    "    c = Counter()\n",
    "    for s in series:\n",
    "        for t in s.split():\n",
    "            c[t] += 1\n",
    "    return c.most_common(topk)\n",
    "\n",
    "if len(fn) > 0:\n",
    "    print(\"\\nTop tokens in Task FALSE NEGATIVES:\")\n",
    "    print(top_tokens(fn['sentence'].tolist(), topk=30))\n",
    "if len(fp) > 0:\n",
    "    print(\"\\nTop tokens in Task FALSE POSITIVES:\")\n",
    "    print(top_tokens(fp['sentence'].tolist(), topk=30))\n",
    "\n",
    "# Date-like detection for tasks (so you can flag/move to deadlines)\n",
    "WEEKDAY_RE = re.compile(r'\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b', re.I)\n",
    "MONTH_RE = re.compile(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b', re.I)\n",
    "TIME_RE = re.compile(r'\\b(?:\\d{1,2}(:\\d{2})?\\s*(am|pm)|am|pm|noon|midnight|eod|cob)\\b', re.I)\n",
    "RELATIVE_RE = re.compile(r'\\b(tomorrow|today|next|in\\s+\\d+\\s+(?:day|days|week|weeks|month|months|hour|hours|minute|minutes))\\b', re.I)\n",
    "NUM_RE = re.compile(r'\\d+')\n",
    "\n",
    "def has_date_like(s):\n",
    "    sl = s.lower()\n",
    "    return bool(WEEKDAY_RE.search(sl) or MONTH_RE.search(sl) or TIME_RE.search(sl) or RELATIVE_RE.search(sl) or NUM_RE.search(sl))\n",
    "\n",
    "# For false negatives: how many were actually date-like? (helps to know if they should be deadlines)\n",
    "if len(fn)>0:\n",
    "    fn['has_date_like'] = fn['sentence'].apply(has_date_like).astype(int)\n",
    "    print(\"\\nFalse negatives with date-like tokens:\", int(fn['has_date_like'].sum()), \"/\", len(fn))\n",
    "    display(fn[fn['has_date_like']==1].sample(min(20, fn['has_date_like'].sum()), random_state=RND)[['sentence_orig','sentence','true','pred']])\n",
    "\n",
    "# For predicted tasks (FPs): how many are questions/deadlines mis-predicted as tasks?\n",
    "if len(fp)>0:\n",
    "    print(\"\\nFP class distribution (what true classes were predicted as task?):\")\n",
    "    print(fp['true'].value_counts().to_dict())\n",
    "    fp['has_date_like'] = fp['sentence'].apply(has_date_like).astype(int)\n",
    "    print(\"FPs containing date-like tokens:\", int(fp['has_date_like'].sum()), \"/\", len(fp))\n",
    "    display(fp.sample(min(20, len(fp)), random_state=RND)[['sentence_orig','sentence','true','pred']])\n",
    "\n",
    "# Feature-level insight: top tokens contributing to 'task' class (requires vectorizers & saved metadata)\n",
    "print(\"\\nAttempting to show top feature tokens for 'task' class (if vectorizers available)...\")\n",
    "feat_names = []\n",
    "try:\n",
    "    # load vectorizers that were used in STEP 3 adjusted\n",
    "    tf_word = joblib.load(MODELS_DIR / \"tfidf_word_adj.joblib\")\n",
    "    tf_char = joblib.load(MODELS_DIR / \"tfidf_char_adj.joblib\") if (MODELS_DIR / \"tfidf_char_adj.joblib\").exists() else None\n",
    "    cue_vec = joblib.load(MODELS_DIR / \"cue_vec_adj.joblib\") if (MODELS_DIR / \"cue_vec_adj.joblib\").exists() else None\n",
    "    meta = json.load(open(MODELS_DIR / \"feature_metadata_adj.json\", 'r', encoding='utf8')) if (MODELS_DIR / \"feature_metadata_adj.json\").exists() else None\n",
    "\n",
    "    # build feature name list in same order as X_all stacking (word, char, cue, engineered)\n",
    "    # word features:\n",
    "    inv_word = {v:k for k,v in tf_word.vocabulary_.items()}\n",
    "    word_dim = len(inv_word)\n",
    "    word_names = [inv_word.get(i, f\"word_{i}\") for i in range(word_dim)]\n",
    "\n",
    "    char_names = []\n",
    "    if tf_char is not None:\n",
    "        inv_char = {v:k for k,v in tf_char.vocabulary_.items()}\n",
    "        char_dim = len(inv_char)\n",
    "        char_names = [inv_char.get(i, f\"char_{i}\") for i in range(char_dim)]\n",
    "\n",
    "    cue_names = cue_vec.get_feature_names_out().tolist() if cue_vec is not None else []\n",
    "\n",
    "    eng_names = meta['engineered_feature_names'] if meta and 'engineered_feature_names' in meta else ['eng_%d' % i for i in range(20)]\n",
    "\n",
    "    feat_names = word_names + char_names + cue_names + eng_names\n",
    "\n",
    "    # load SVC coefficients: prefer calibrated wrapper's base_estimator else svc file\n",
    "    if cal is not None:\n",
    "        base = cal.base_estimator\n",
    "    else:\n",
    "        base = svc\n",
    "    coefs = base.coef_  # shape (n_classes, n_features)\n",
    "    classes = base.classes_\n",
    "    # find index of 'task' class\n",
    "    idx_task = list(classes).index('task')\n",
    "    task_coefs = coefs[idx_task]\n",
    "    # top positive features pushing toward 'task'\n",
    "    top_pos_idx = np.argsort(task_coefs)[-40:][::-1]\n",
    "    top_neg_idx = np.argsort(task_coefs)[:40]\n",
    "    print(\"\\nTop positive features for 'task' (tokens/engineered features):\")\n",
    "    for i in top_pos_idx[:40]:\n",
    "        name = feat_names[i] if i < len(feat_names) else f\"f_{i}\"\n",
    "        print(i, name, float(task_coefs[i]))\n",
    "    print(\"\\nTop negative features (push away from 'task'):\")\n",
    "    for i in top_neg_idx[:40]:\n",
    "        name = feat_names[i] if i < len(feat_names) else f\"f_{i}\"\n",
    "        print(i, name, float(task_coefs[i]))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Could not show detailed feature tokens (missing vectorizers/metadata or mismatch). Error:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a061ed3-ef89-4173-bae2-c7cd3bfa5d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded calibrated model: svc_calibrated_adj.joblib\n",
      "Model expects n_features_in_ = 130036\n",
      "Loaded vectorizers; word_dim= 100000  char_dim= 30000  cue_dim= 21\n",
      "Dataset total rows: 826026\n",
      "Using sample size: 826026\n",
      "Engineered features built shape: (826026, 17)\n",
      "Component dims -> word: 100000 char: 30000 cue: 21 eng: 17\n",
      "Model expects total features: 130036 ; sum(word+char+cue) = 130021 => expected engineered dims = 15\n",
      "Trimming engineered features: 17 -> 15\n",
      "Saved predictions to: models/final_predictions_after_step4.csv\n",
      "\n",
      "Classification report (on sample):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    deadline     0.9997    1.0000    0.9998      9446\n",
      "    question     0.9997    0.9997    0.9997    806584\n",
      "        task     0.9759    0.9772    0.9766      9996\n",
      "\n",
      "    accuracy                         0.9994    826026\n",
      "   macro avg     0.9918    0.9923    0.9920    826026\n",
      "weighted avg     0.9994    0.9994    0.9994    826026\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_orig</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>label_source</th>\n",
       "      <th>pred</th>\n",
       "      <th>p_deadline</th>\n",
       "      <th>p_question</th>\n",
       "      <th>p_task</th>\n",
       "      <th>possible_deadline_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rearrange closet</td>\n",
       "      <td>rearrange closet</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.978440</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meeting tasks</td>\n",
       "      <td>meeting tasks</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>taste of home</td>\n",
       "      <td>taste of home</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.179435</td>\n",
       "      <td>0.820550</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bring book in</td>\n",
       "      <td>bring book in</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sociology paper</td>\n",
       "      <td>sociology paper</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.043721</td>\n",
       "      <td>0.956274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paper hold</td>\n",
       "      <td>paper hold</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.134310</td>\n",
       "      <td>0.865680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>osteopath</td>\n",
       "      <td>osteopath</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.926368</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fix tv remote</td>\n",
       "      <td>fix tv remote</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.996790</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>put on license sticker</td>\n",
       "      <td>put on license sticker</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.062424</td>\n",
       "      <td>0.937563</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text nazgul</td>\n",
       "      <td>text nazgul</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>0.986338</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>buy envelops</td>\n",
       "      <td>buy envelops</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mom application</td>\n",
       "      <td>mom application</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.997464</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>girls shoes</td>\n",
       "      <td>girls shoes</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.989020</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>book</td>\n",
       "      <td>book</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drop off dogs</td>\n",
       "      <td>drop off dogs</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.058678</td>\n",
       "      <td>0.941312</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>creative review</td>\n",
       "      <td>creative review</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>0.991553</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>roettger turkey</td>\n",
       "      <td>roettger turkey</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.094475</td>\n",
       "      <td>0.905519</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>finish udemy course</td>\n",
       "      <td>finish udemy course</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.997645</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>check garage door</td>\n",
       "      <td>check garage door</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>monthly comms</td>\n",
       "      <td>monthly comms</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.151704</td>\n",
       "      <td>0.848282</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>office layout</td>\n",
       "      <td>office layout</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.124372</td>\n",
       "      <td>0.875620</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>start sop</td>\n",
       "      <td>start sop</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.994532</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>report time</td>\n",
       "      <td>report time</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.160360</td>\n",
       "      <td>0.839436</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>office attire</td>\n",
       "      <td>office attire</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.034224</td>\n",
       "      <td>0.965767</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dining room windows</td>\n",
       "      <td>dining room windows</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.916479</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>electronic recycle</td>\n",
       "      <td>electronic recycle</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.306769</td>\n",
       "      <td>0.693228</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>heathrow express tix</td>\n",
       "      <td>heathrow express tix</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.154588</td>\n",
       "      <td>0.845403</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5x tshirts</td>\n",
       "      <td>5x tshirts</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.038624</td>\n",
       "      <td>0.961198</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>call 8</td>\n",
       "      <td>call 8</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>eat cucumbers</td>\n",
       "      <td>eat cucumbers</td>\n",
       "      <td>task</td>\n",
       "      <td>mslatte</td>\n",
       "      <td>task</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.144501</td>\n",
       "      <td>0.855492</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sentence_orig                sentence label label_source  pred  \\\n",
       "0         rearrange closet        rearrange closet  task      mslatte  task   \n",
       "1            meeting tasks           meeting tasks  task      mslatte  task   \n",
       "2            taste of home           taste of home  task      mslatte  task   \n",
       "3            bring book in           bring book in  task      mslatte  task   \n",
       "4          sociology paper         sociology paper  task      mslatte  task   \n",
       "5               paper hold              paper hold  task      mslatte  task   \n",
       "6                osteopath               osteopath  task      mslatte  task   \n",
       "7            fix tv remote           fix tv remote  task      mslatte  task   \n",
       "8   put on license sticker  put on license sticker  task      mslatte  task   \n",
       "9              text nazgul             text nazgul  task      mslatte  task   \n",
       "10            buy envelops            buy envelops  task      mslatte  task   \n",
       "11         mom application         mom application  task      mslatte  task   \n",
       "12             girls shoes             girls shoes  task      mslatte  task   \n",
       "13                    book                    book  task      mslatte  task   \n",
       "14           drop off dogs           drop off dogs  task      mslatte  task   \n",
       "15         creative review         creative review  task      mslatte  task   \n",
       "16         roettger turkey         roettger turkey  task      mslatte  task   \n",
       "17     finish udemy course     finish udemy course  task      mslatte  task   \n",
       "18       check garage door       check garage door  task      mslatte  task   \n",
       "19           monthly comms           monthly comms  task      mslatte  task   \n",
       "20           office layout           office layout  task      mslatte  task   \n",
       "21               start sop               start sop  task      mslatte  task   \n",
       "22             report time             report time  task      mslatte  task   \n",
       "23           office attire           office attire  task      mslatte  task   \n",
       "24     dining room windows     dining room windows  task      mslatte  task   \n",
       "25      electronic recycle      electronic recycle  task      mslatte  task   \n",
       "26    heathrow express tix    heathrow express tix  task      mslatte  task   \n",
       "27              5x tshirts              5x tshirts  task      mslatte  task   \n",
       "28                  call 8                  call 8  task      mslatte  task   \n",
       "29           eat cucumbers           eat cucumbers  task      mslatte  task   \n",
       "\n",
       "    p_deadline  p_question    p_task  possible_deadline_flag  \n",
       "0     0.000005    0.021555  0.978440                   False  \n",
       "1     0.000032    0.019737  0.980231                   False  \n",
       "2     0.000015    0.179435  0.820550                   False  \n",
       "3     0.000104    0.000117  0.999779                   False  \n",
       "4     0.000005    0.043721  0.956274                   False  \n",
       "5     0.000010    0.134310  0.865680                   False  \n",
       "6     0.000002    0.073629  0.926368                   False  \n",
       "7     0.001140    0.002070  0.996790                   False  \n",
       "8     0.000013    0.062424  0.937563                   False  \n",
       "9     0.000016    0.013646  0.986338                   False  \n",
       "10    0.000027    0.000029  0.999944                   False  \n",
       "11    0.000684    0.001852  0.997464                   False  \n",
       "12    0.000017    0.010962  0.989020                   False  \n",
       "13    0.000025    0.000002  0.999973                   False  \n",
       "14    0.000011    0.058678  0.941312                   False  \n",
       "15    0.000041    0.008406  0.991553                   False  \n",
       "16    0.000006    0.094475  0.905519                   False  \n",
       "17    0.000041    0.002313  0.997645                   False  \n",
       "18    0.000009    0.001851  0.998141                   False  \n",
       "19    0.000014    0.151704  0.848282                   False  \n",
       "20    0.000008    0.124372  0.875620                   False  \n",
       "21    0.000012    0.005457  0.994532                   False  \n",
       "22    0.000205    0.160360  0.839436                   False  \n",
       "23    0.000009    0.034224  0.965767                   False  \n",
       "24    0.000003    0.083518  0.916479                   False  \n",
       "25    0.000003    0.306769  0.693228                   False  \n",
       "26    0.000008    0.154588  0.845403                   False  \n",
       "27    0.000178    0.038624  0.961198                   False  \n",
       "28    0.000244    0.000001  0.999754                   False  \n",
       "29    0.000007    0.144501  0.855492                   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FINAL INFERENCE & EXPORT \n",
    "# - Uses calibrated classifier if available\n",
    "# Predicts on sample (5k) and saves CSV to models/final_predictions_after_step4.csv\n",
    "import joblib, json, re, traceback\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "COMBINED_CSV = Path(\"data/processed/combined_dataset.csv\")\n",
    "OUT_CSV = MODELS_DIR / \"final_predictions_after_step4.csv\"\n",
    "\n",
    "#adjust SAMPLE_LIMIT=None to run on full dataset (VERY SLOw)\n",
    "SAMPLE_LIMIT = None\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "model = None\n",
    "cal_paths = [\n",
    "    MODELS_DIR / \"svc_calibrated_with_timex_spacy.joblib\",\n",
    "    MODELS_DIR / \"svc_calibrated_adj.joblib\",\n",
    "    MODELS_DIR / \"svc_calibrated_small.joblib\"\n",
    "]\n",
    "svc_paths = [\n",
    "    MODELS_DIR / \"svc_with_timex_spacy.joblib\",\n",
    "    MODELS_DIR / \"svc_adj.joblib\",\n",
    "    MODELS_DIR / \"svc_small.joblib\",\n",
    "    MODELS_DIR / \"sgd_partial_adj.joblib\",\n",
    "    MODELS_DIR / \"sgd_partial.joblib\"\n",
    "]\n",
    "\n",
    "for p in cal_paths:\n",
    "    if p.exists():\n",
    "        model = joblib.load(p)\n",
    "        print(\"Loaded calibrated model:\", p.name)\n",
    "        break\n",
    "if model is None:\n",
    "    for p in svc_paths:\n",
    "        if p.exists():\n",
    "            model = joblib.load(p)\n",
    "            print(\"Loaded model:\", p.name)\n",
    "            break\n",
    "if model is None:\n",
    "    raise RuntimeError(\"No model found in models/. Expected one of: \" + \", \".join([str(x) for x in cal_paths+svc_paths]))\n",
    "\n",
    "# determine model expected input feature count robustly\n",
    "expected_nfeat = getattr(model, \"n_features_in_\", None)\n",
    "if expected_nfeat is None:\n",
    "    # try to extract from underlying calibrated estimators if present\n",
    "    try:\n",
    "        if hasattr(model, \"calibrated_classifiers_\") and len(model.calibrated_classifiers_)>0:\n",
    "            # calibrated_classifiers_[0] is a _CalibratedClassifier; its 'estimator' should be the underlying fitted estimator\n",
    "            first = model.calibrated_classifiers_[0]\n",
    "            est = getattr(first, \"estimator\", None)\n",
    "            if est is not None:\n",
    "                expected_nfeat = getattr(est, \"n_features_in_\", None)\n",
    "    except Exception:\n",
    "        expected_nfeat = None\n",
    "if expected_nfeat is None:\n",
    "    # try base_estimator fallback (some versions)\n",
    "    try:\n",
    "        expected_nfeat = getattr(model.base_estimator, \"n_features_in_\", None)\n",
    "    except Exception:\n",
    "        expected_nfeat = None\n",
    "\n",
    "if expected_nfeat is None:\n",
    "    raise RuntimeError(\"Could not determine model.n_features_in_. Model may be incompatible or unfit.\")\n",
    "\n",
    "print(\"Model expects n_features_in_ =\", expected_nfeat)\n",
    "tf_word_path = MODELS_DIR / \"tfidf_word_adj.joblib\"\n",
    "tf_char_path = MODELS_DIR / \"tfidf_char_adj.joblib\"\n",
    "cue_path = MODELS_DIR / \"cue_vec_adj.joblib\"\n",
    "meta_path = MODELS_DIR / \"feature_metadata_adj.json\"\n",
    "\n",
    "for p in (tf_word_path, cue_path, meta_path):\n",
    "    if not p.exists():\n",
    "        raise RuntimeError(f\"Missing required artifact: {p}\")\n",
    "\n",
    "tf_word = joblib.load(tf_word_path)\n",
    "tf_char = joblib.load(tf_char_path) if tf_char_path.exists() else None\n",
    "cue_vec = joblib.load(cue_path)\n",
    "meta = json.load(open(meta_path, 'r', encoding='utf8'))\n",
    "\n",
    "print(\"Loaded vectorizers; word_dim=\", len(tf_word.vocabulary_), \n",
    "      \" char_dim=\", (len(tf_char.vocabulary_) if tf_char is not None else 0),\n",
    "      \" cue_dim=\", cue_vec.get_feature_names_out().shape[0])\n",
    "\n",
    "df = pd.read_csv(COMBINED_CSV, dtype=str, keep_default_na=False)\n",
    "n_total = len(df)\n",
    "print(\"Dataset total rows:\", n_total)\n",
    "if SAMPLE_LIMIT is None:\n",
    "    sample_df = df.reset_index(drop=True)\n",
    "else:\n",
    "    sample_df = df.sample(min(SAMPLE_LIMIT, n_total), random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "print(\"Using sample size:\", len(sample_df))\n",
    "\n",
    "sentences = sample_df['sentence'].astype(str).tolist()\n",
    "\n",
    "NUM_RE = re.compile(r'\\d+')\n",
    "QUESTION_RE = re.compile(r'\\?|\\b(who|what|when|where|why|how|which)\\b', re.I)\n",
    "IMPERATIVE_RE = re.compile(r'^(submit|finish|complete|turn|send|email|deliver|make|do|create|update|fix|upload|prepare|post|hand in|return)\\b', re.I)\n",
    "\n",
    "def engineered_inference(sent_list_local, df_local=None):\n",
    "    rows=[]\n",
    "    for i, s in enumerate(sent_list_local):\n",
    "        sl = s.lower()\n",
    "        tokens = sl.split()\n",
    "        tc = max(1, len(tokens))\n",
    "        num_digits = 1 if NUM_RE.search(sl) else 0\n",
    "        has_weekday = 1 if re.search(r'\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b', sl, re.I) else 0\n",
    "        has_month = 1 if re.search(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\b', sl, re.I) else 0\n",
    "        has_time = 1 if re.search(r'\\b(?:\\d{1,2}(:\\d{2})?\\s*(am|pm)|am|pm|noon|midnight|eod|cob)\\b', sl, re.I) else 0\n",
    "        has_relative = 1 if re.search(r'\\b(tomorrow|today|next|in\\s+\\d+\\s+(?:day|days|week|weeks|month|months|hour|hours|minute|minutes))\\b', sl, re.I) else 0\n",
    "        has_question = 1 if QUESTION_RE.search(sl) else 0\n",
    "        starts_imp = 1 if IMPERATIVE_RE.match(sl) else 0\n",
    "        has_duration = 1 if re.search(r'\\b(hour|hours|minute|minutes|day|days|week|weeks|month|months|year|years)\\b', sl, re.I) else 0\n",
    "        has_currency = 1 if re.search(r'[$£€¥]|usd|aud|gbp|cad', sl, re.I) else 0\n",
    "        has_url_email = 1 if re.search(r'http[s]?://|www\\.|@', sl, re.I) else 0\n",
    "        q_marks = len(re.findall(r'\\?', sl))\n",
    "        avg_token_len = float(sum(len(t) for t in tokens) / tc)\n",
    "        unique_ratio = float(len(set(tokens)) / tc)\n",
    "        numeric_ratio = float(sum(1 for t in tokens if NUM_RE.fullmatch(t)) / tc)\n",
    "        # optional parsed_date_flag / spaCy flags - include only if in df_local\n",
    "        parsed_date = int(df_local.loc[i,'parsed_date_flag']) if (df_local is not None and 'parsed_date_flag' in df_local.columns) else 0\n",
    "        has_date_ent = int(df_local.loc[i,'has_date_ent']) if (df_local is not None and 'has_date_ent' in df_local.columns) else 0\n",
    "        rows.append([\n",
    "            tc, avg_token_len, unique_ratio, numeric_ratio, num_digits,\n",
    "            has_weekday, has_month, has_time, has_relative, has_duration,\n",
    "            has_question, starts_imp, has_currency, has_url_email, q_marks,\n",
    "            parsed_date, has_date_ent\n",
    "        ])\n",
    "    return np.array(rows, dtype=float)\n",
    "\n",
    "Xeng = engineered_inference(sentences, df_local=sample_df)\n",
    "eng_dim = Xeng.shape[1]\n",
    "print(\"Engineered features built shape:\", Xeng.shape)\n",
    "\n",
    "Xw = tf_word.transform(sentences).astype(np.float32)\n",
    "word_dim = Xw.shape[1]\n",
    "Xc = tf_char.transform(sentences).astype(np.float32) if tf_char is not None else None\n",
    "char_dim = Xc.shape[1] if Xc is not None else 0\n",
    "Xcue = cue_vec.transform(sentences).astype(np.float32)\n",
    "cue_dim = Xcue.shape[1]\n",
    "\n",
    "print(\"Component dims -> word:\", word_dim, \"char:\", char_dim, \"cue:\", cue_dim, \"eng:\", eng_dim)\n",
    "\n",
    "sum_sparse = word_dim + char_dim + cue_dim\n",
    "expected_eng_dim = expected_nfeat - sum_sparse\n",
    "print(\"Model expects total features:\", expected_nfeat, \"; sum(word+char+cue) =\", sum_sparse,\n",
    "      \"=> expected engineered dims =\", expected_eng_dim)\n",
    "\n",
    "if expected_eng_dim < 0:\n",
    "    raise RuntimeError(f\"Model expects fewer sparse features ({expected_nfeat}) than sum of word/char/cue ({sum_sparse}). Check vectorizers and model consistency.\")\n",
    "\n",
    "if eng_dim > expected_eng_dim:\n",
    "    # trim rightmost engineered columns\n",
    "    Xeng_aligned = Xeng[:, :expected_eng_dim]\n",
    "    print(f\"Trimming engineered features: {eng_dim} -> {expected_eng_dim}\")\n",
    "elif eng_dim < expected_eng_dim:\n",
    "    # pad with zeros\n",
    "    pad_width = expected_eng_dim - eng_dim\n",
    "    pad = np.zeros((Xeng.shape[0], pad_width), dtype=float)\n",
    "    Xeng_aligned = np.hstack([Xeng, pad])\n",
    "    print(f\"Padding engineered features: {eng_dim} -> {expected_eng_dim} (pad {pad_width} columns)\")\n",
    "else:\n",
    "    Xeng_aligned = Xeng\n",
    "\n",
    "# convert engineered to sparse and stack in the exact training order: word, char(if present), cue, engineered\n",
    "from scipy.sparse import csr_matrix\n",
    "components = [csr_matrix(Xw)]\n",
    "if Xc is not None:\n",
    "    components.append(csr_matrix(Xc))\n",
    "components.append(csr_matrix(Xcue))\n",
    "components.append(csr_matrix(Xeng_aligned))\n",
    "X_sample = hstack(components, format='csr')\n",
    "\n",
    "if X_sample.shape[1] != expected_nfeat:\n",
    "    raise RuntimeError(f\"Feature alignment failed: X_sample has {X_sample.shape[1]} features but model expects {expected_nfeat}.\")\n",
    "\n",
    "if hasattr(model, \"predict_proba\"):\n",
    "    y_proba = model.predict_proba(X_sample)\n",
    "    y_pred = model.predict(X_sample)\n",
    "else:\n",
    "    y_pred = model.predict(X_sample)\n",
    "    y_proba = None\n",
    "\n",
    "out = sample_df[['sentence_orig','sentence','label','label_source']].copy()\n",
    "out['pred'] = y_pred\n",
    "if y_proba is not None:\n",
    "    classes = model.classes_.tolist()\n",
    "    for i, c in enumerate(classes):\n",
    "        out[f\"p_{c}\"] = y_proba[:, i]\n",
    "# simple heuristic date regex for flagging tasks\n",
    "DATE_REGEX = re.compile(r'\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday|january|february|march|april|may|june|july|august|september|october|november|december|\\d{1,2}(:\\d{2})?\\s*(am|pm)|tomorrow|today|next|in\\s+\\d+\\s+(?:day|days|week|weeks|month|months))\\b', re.I)\n",
    "out['possible_deadline_flag'] = [(p == 'task') and bool(DATE_REGEX.search(s.lower())) for p, s in zip(out['pred'], out['sentence'])]\n",
    "\n",
    "out.to_csv(OUT_CSV, index=False, encoding='utf8')\n",
    "print(\"Saved predictions to:\", OUT_CSV)\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"\\nClassification report (on sample):\")\n",
    "    print(classification_report(out['label'], out['pred'], digits=4))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "display(out.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b419fd6-9367-49c1-86fc-66e98801fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFINED single-note classifier with robust deadline heuristic\n",
    "import re, joblib, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "TF_WORD = MODELS_DIR / \"tfidf_word_adj.joblib\"\n",
    "TF_CHAR = MODELS_DIR / \"tfidf_char_adj.joblib\"\n",
    "CUE_VEC = MODELS_DIR / \"cue_vec_adj.joblib\"\n",
    "META = MODELS_DIR / \"feature_metadata_adj.json\"\n",
    "\n",
    "def _load_model_and_vecs():\n",
    "    # model candidates (calibrated preferred)\n",
    "    cand = [\n",
    "        MODELS_DIR / \"svc_calibrated_with_timex_spacy.joblib\",\n",
    "        MODELS_DIR / \"svc_calibrated_adj.joblib\",\n",
    "        MODELS_DIR / \"svc_calibrated_small.joblib\",\n",
    "        MODELS_DIR / \"svc_with_timex_spacy.joblib\",\n",
    "        MODELS_DIR / \"svc_adj.joblib\",\n",
    "        MODELS_DIR / \"svc_small.joblib\",\n",
    "        MODELS_DIR / \"sgd_partial_adj.joblib\",\n",
    "        MODELS_DIR / \"sgd_partial.joblib\"\n",
    "    ]\n",
    "    model = None\n",
    "    model_name = None\n",
    "    for p in cand:\n",
    "        if p.exists():\n",
    "            model = joblib.load(p)\n",
    "            model_name = p.name\n",
    "            break\n",
    "    if model is None:\n",
    "        raise FileNotFoundError(\"No model found in models/.\")\n",
    "    if not TF_WORD.exists() or not CUE_VEC.exists() or not META.exists():\n",
    "        raise FileNotFoundError(\"Missing vectorizers/metadata in models/. Expected tfidf_word_adj.joblib, cue_vec_adj.joblib, feature_metadata_adj.json.\")\n",
    "    tf_word = joblib.load(TF_WORD)\n",
    "    tf_char = joblib.load(TF_CHAR) if TF_CHAR.exists() else None\n",
    "    cue_vec = joblib.load(CUE_VEC)\n",
    "    meta = json.load(open(META, 'r', encoding='utf8'))\n",
    "    return model, model_name, tf_word, tf_char, cue_vec, meta\n",
    "\n",
    "WEEKDAY_RE = re.compile(r'(monday|tuesday|wednesday|thursday|friday|saturday|sunday)', re.I)  # substring match on purpose\n",
    "RELATIVE_RE = re.compile(r'\\b(tomorrow|today|tonight|this\\s+(morning|afternoon|evening)|next week|next month|next year|next\\b|in\\s+\\d+\\s+(?:day|days|week|weeks|month|months|hour|hours|minute|minutes))\\b', re.I)\n",
    "MONTH_DAY_RE = re.compile(r'\\b(january|february|march|april|may|june|july|august|september|october|november|december)\\s+([1-9]|[12][0-9]|3[01])(st|nd|rd|th)?\\b', re.I)\n",
    "# ordinal up to 31 (1st..31st), will not match 245th or whatev\n",
    "ORDINAL_RE = re.compile(r'\\b([1-9]|[12][0-9]|3[01])(st|nd|rd|th)\\b', re.I)\n",
    "# numbers 1-31 in context: \"on 24\", \"on the 24\", \"by 5\", \"due 7th\" etc.\n",
    "CONTEXT_NUM_RE = re.compile(r'\\b(?:on|by|due|before|until|next|this|in)\\s+(?:the\\s+)?([1-9]|[12][0-9]|3[01])(?:\\b|[^0-9])', re.I)\n",
    "# month/day numeric like 12/24 or 24/12\n",
    "SLASH_DATE_RE = re.compile(r'\\b([0-3]?\\d)[/-]([01]?\\d)\\b')\n",
    "# explicit cues that strongly indicate deadlines\n",
    "DEADLINE_CUES = re.compile(r'\\b(due|deadline|no later than|eod|cob|by\\b|before\\b|until\\b)\\b', re.I)\n",
    "\n",
    "def is_likely_deadline(text):\n",
    "    s = (text or \"\").lower()\n",
    "    # quick reject if empty\n",
    "    if not s.strip():\n",
    "        return False, None\n",
    "    # check strong cues first\n",
    "    if DEADLINE_CUES.search(s):\n",
    "        return True, \"deadline_cue\"\n",
    "    if WEEKDAY_RE.search(s):\n",
    "        return True, \"weekday\"\n",
    "    if RELATIVE_RE.search(s):\n",
    "        return True, \"relative_phrase\"\n",
    "    if MONTH_DAY_RE.search(s):\n",
    "        return True, \"month_day\"\n",
    "    if ORDINAL_RE.search(s):\n",
    "        return True, \"ordinal_1_31\"\n",
    "    if CONTEXT_NUM_RE.search(s):\n",
    "        return True, \"context_number_1_31\"\n",
    "    if SLASH_DATE_RE.search(s):\n",
    "        return True, \"slash_date\"\n",
    "    return False, None\n",
    "\n",
    "# lightweight engineered feature builder (keeps same ordering as training)\n",
    "def _engineered_features_one(s, parsed_date_flag=0, has_date_ent=0):\n",
    "    sl = (s or \"\").lower()\n",
    "    tokens = sl.split()\n",
    "    tc = max(1, len(tokens))\n",
    "    num_digits = 1 if re.search(r'\\d+', sl) else 0\n",
    "    avg_token_len = float(sum(len(t) for t in tokens) / tc)\n",
    "    unique_ratio = float(len(set(tokens)) / tc)\n",
    "    numeric_ratio = float(sum(1 for t in tokens if re.fullmatch(r'\\d+', t)) / tc)\n",
    "    has_weekday = 1 if WEEKDAY_RE.search(sl) else 0\n",
    "    has_month = 1 if re.search(r'(january|february|march|april|may|june|july|august|september|october|november|december)', sl, re.I) else 0\n",
    "    has_time = 1 if re.search(r'\\b(?:\\d{1,2}(:\\d{2})?\\s*(am|pm)|noon|midnight|eod|cob)\\b', sl, re.I) else 0\n",
    "    has_relative = 1 if RELATIVE_RE.search(sl) else 0\n",
    "    has_duration = 1 if re.search(r'\\b(hour|hours|minute|minutes|day|days|week|weeks|month|months|year|years)\\b', sl, re.I) else 0\n",
    "    has_question = 1 if re.search(r'\\?|\\b(who|what|when|where|why|how|which)\\b', sl, re.I) else 0\n",
    "    starts_imp = 1 if re.match(r'^(submit|finish|complete|turn|send|email|deliver|make|do|create|update|fix|upload|prepare|post|hand in|return)\\b', sl, re.I) else 0\n",
    "    has_currency = 1 if re.search(r'[$£€¥]|usd|aud|gbp|cad', sl, re.I) else 0\n",
    "    has_url_email = 1 if re.search(r'http[s]?://|www\\.|@', sl, re.I) else 0\n",
    "    q_marks = len(re.findall(r'\\?', sl))\n",
    "    return np.array([\n",
    "        tc, avg_token_len, unique_ratio, numeric_ratio, num_digits,\n",
    "        has_weekday, has_month, has_time, has_relative, has_duration,\n",
    "        has_question, starts_imp, has_currency, has_url_email, q_marks,\n",
    "        int(parsed_date_flag), int(has_date_ent)\n",
    "    ], dtype=float).reshape(1, -1)\n",
    "\n",
    "# the main wrapper that classifies a single note and enforces the \"task->deadline\" override rule\n",
    "def classify_note_refined(note_text):\n",
    "    model, model_name, tf_word, tf_char, cue_vec, meta = _load_model_and_vecs()\n",
    "    s = str(note_text or \"\")\n",
    "    # lexical transforms\n",
    "    Xw = tf_word.transform([s]).astype(np.float32)\n",
    "    Xc = tf_char.transform([s]).astype(np.float32) if tf_char is not None else None\n",
    "    Xcue = cue_vec.transform([s]).astype(np.float32)\n",
    "    # engineered features (we don't have parsed_date_flag/has_date_ent here; set 0)\n",
    "    eng = _engineered_features_one(s, parsed_date_flag=0, has_date_ent=0)\n",
    "    # align engineered to model expected dims similar to earlier logic\n",
    "    expected_nfeat = getattr(model, \"n_features_in_\", None)\n",
    "    if expected_nfeat is None:\n",
    "        # try calibrated inner estimator if needed\n",
    "        if hasattr(model, 'calibrated_classifiers_') and len(model.calibrated_classifiers_)>0:\n",
    "            est = getattr(model.calibrated_classifiers_[0], 'estimator', None)\n",
    "            expected_nfeat = getattr(est, 'n_features_in_', None)\n",
    "        elif hasattr(model, 'base_estimator'):\n",
    "            expected_nfeat = getattr(model.base_estimator, 'n_features_in_', None)\n",
    "    if expected_nfeat is None:\n",
    "        raise RuntimeError(\"Cannot determine expected feature count for model.\")\n",
    "    word_dim = Xw.shape[1]\n",
    "    char_dim = Xc.shape[1] if Xc is not None else 0\n",
    "    cue_dim = Xcue.shape[1]\n",
    "    sum_sparse = word_dim + char_dim + cue_dim\n",
    "    expected_eng = expected_nfeat - sum_sparse\n",
    "    if expected_eng < 0:\n",
    "        raise RuntimeError(\"Vectorizer/model mismatch: model expects fewer sparse features than available.\")\n",
    "    # pad/trim engineered\n",
    "    if eng.shape[1] > expected_eng:\n",
    "        eng_al = eng[:, :expected_eng]\n",
    "    elif eng.shape[1] < expected_eng:\n",
    "        pad = np.zeros((1, expected_eng - eng.shape[1]), dtype=float)\n",
    "        eng_al = np.hstack([eng, pad])\n",
    "    else:\n",
    "        eng_al = eng\n",
    "    # assemble final X\n",
    "    from scipy.sparse import csr_matrix\n",
    "    comps = [csr_matrix(Xw)]\n",
    "    if Xc is not None:\n",
    "        comps.append(csr_matrix(Xc))\n",
    "    comps.append(csr_matrix(Xcue))\n",
    "    comps.append(csr_matrix(eng_al))\n",
    "    X_in = hstack(comps, format='csr')\n",
    "    # predict\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs_arr = model.predict_proba(X_in)[0]\n",
    "        classes = list(model.classes_)\n",
    "        probs = dict(zip(classes, [float(x) for x in probs_arr]))\n",
    "        pred_label = max(probs.items(), key=lambda x: x[1])[0]\n",
    "    else:\n",
    "        pred_label = model.predict(X_in)[0]\n",
    "        probs = None\n",
    "    # apply refined deadline rule only when model predicted 'task'\n",
    "    is_date, reason = is_likely_deadline(s)\n",
    "    possible_deadline_flag = False\n",
    "    disclaimer = None\n",
    "    if pred_label == 'task' and is_date:\n",
    "        # only flag; do not change model label; include clear disclaimer\n",
    "        possible_deadline_flag = True\n",
    "        disclaimer = f\"Predicted 'task' by model, but text matches a date-like pattern ({reason}); likely a deadline. Review or relabel manually.\"\n",
    "    # return structured result and print concise line\n",
    "    out = {\n",
    "        'pred': pred_label,\n",
    "        'probs': probs,\n",
    "        'possible_deadline_flag': possible_deadline_flag,\n",
    "        'deadline_reason': reason,\n",
    "        'disclaimer': disclaimer,\n",
    "        'model_name': model_name\n",
    "    }\n",
    "    # concise output to user\n",
    "    print(\"PRED:\", out['pred'], \" DEADLINE_FLAG:\", out['possible_deadline_flag'])\n",
    "    if out['probs'] is not None:\n",
    "        print(\"PROBS:\", out['probs'])\n",
    "    if out['possible_deadline_flag']:\n",
    "        print(\"NOTICE:\", out['disclaimer'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "accaddf5-a2b9-4a5d-85f7-9ed3a79a3f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: question  DEADLINE_FLAG: False\n",
      "PROBS: {'deadline': 3.468707832668601e-06, 'question': 0.9999965148461607, 'task': 1.644600660436486e-08}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'question',\n",
       " 'probs': {'deadline': 3.468707832668601e-06,\n",
       "  'question': 0.9999965148461607,\n",
       "  'task': 1.644600660436486e-08},\n",
       " 'possible_deadline_flag': False,\n",
       " 'deadline_reason': None,\n",
       " 'disclaimer': None,\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"what is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9047ccb6-4f30-41d8-8f0b-58c44742bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: task  DEADLINE_FLAG: True\n",
      "PROBS: {'deadline': 0.0003333120631012992, 'question': 0.011713043568840554, 'task': 0.9879536443680582}\n",
      "NOTICE: Predicted 'task' by model, but text matches a date-like pattern (ordinal_1_31); likely a deadline. Review or relabel manually.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'task',\n",
       " 'probs': {'deadline': 0.0003333120631012992,\n",
       "  'question': 0.011713043568840554,\n",
       "  'task': 0.9879536443680582},\n",
       " 'possible_deadline_flag': True,\n",
       " 'deadline_reason': 'ordinal_1_31',\n",
       " 'disclaimer': \"Predicted 'task' by model, but text matches a date-like pattern (ordinal_1_31); likely a deadline. Review or relabel manually.\",\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"go dmv 24th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b12b6cf9-61c5-4222-accf-0bc2bde68020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: task  DEADLINE_FLAG: False\n",
      "PROBS: {'deadline': 6.417157361867797e-06, 'question': 1.6997595333749698e-05, 'task': 0.9999765852473043}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'task',\n",
       " 'probs': {'deadline': 6.417157361867797e-06,\n",
       "  'question': 1.6997595333749698e-05,\n",
       "  'task': 0.9999765852473043},\n",
       " 'possible_deadline_flag': False,\n",
       " 'deadline_reason': None,\n",
       " 'disclaimer': None,\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"certificate get\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9352f2f2-b7ae-440e-b589-d44a484c16d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: deadline  DEADLINE_FLAG: False\n",
      "PROBS: {'deadline': 0.9148061549078147, 'question': 0.0038982786261954117, 'task': 0.08129556646598997}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'deadline',\n",
       " 'probs': {'deadline': 0.9148061549078147,\n",
       "  'question': 0.0038982786261954117,\n",
       "  'task': 0.08129556646598997},\n",
       " 'possible_deadline_flag': False,\n",
       " 'deadline_reason': 'deadline_cue',\n",
       " 'disclaimer': None,\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"eat by Monday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1152aae-c5ba-41a9-94dc-7fa7b803c5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: task  DEADLINE_FLAG: False\n",
      "PROBS: {'deadline': 0.00025997871884084374, 'question': 0.017296964115529476, 'task': 0.9824430571656297}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'task',\n",
       " 'probs': {'deadline': 0.00025997871884084374,\n",
       "  'question': 0.017296964115529476,\n",
       "  'task': 0.9824430571656297},\n",
       " 'possible_deadline_flag': False,\n",
       " 'deadline_reason': None,\n",
       " 'disclaimer': None,\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"go to class on the 234th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65472b19-203d-4665-a6e8-52a32870ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: question  DEADLINE_FLAG: False\n",
      "PROBS: {'deadline': 2.5695786205867577e-05, 'question': 0.9658869354221621, 'task': 0.034087368791632114}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'question',\n",
       " 'probs': {'deadline': 2.5695786205867577e-05,\n",
       "  'question': 0.9658869354221621,\n",
       "  'task': 0.034087368791632114},\n",
       " 'possible_deadline_flag': False,\n",
       " 'deadline_reason': None,\n",
       " 'disclaimer': None,\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"def potato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cef7e301-a4c3-4242-a37d-e9a8afb0d28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED: question  DEADLINE_FLAG: False\n",
      "PROBS: {'deadline': 8.493976906837742e-06, 'question': 0.9824549498754939, 'task': 0.017536556147599386}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pred': 'question',\n",
       " 'probs': {'deadline': 8.493976906837742e-06,\n",
       "  'question': 0.9824549498754939,\n",
       "  'task': 0.017536556147599386},\n",
       " 'possible_deadline_flag': False,\n",
       " 'deadline_reason': None,\n",
       " 'disclaimer': None,\n",
       " 'model_name': 'svc_calibrated_adj.joblib'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_note_refined(\"meanin of Google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4aa5a1-9479-4161-9114-13c62e855492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
